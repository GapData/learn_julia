{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisson codes\n",
    "\n",
    "\n",
    "There is a significant speedup but...  what is the most impactful change in the code?\n",
    "\n",
    "Some comments\n",
    "\n",
    "- Use **```A .+= b ```** instead of **```A += b ```** the first one allocates less memory.\n",
    "\n",
    "\n",
    "#### Different progressive steps to imporve speed\n",
    "\n",
    "Version 1) defined beforehand the arrays that are used inside the for loop.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "# Generate data that will be used later\n",
    "X_train = rand(5000,784);\n",
    "X_batch_col = X_train'[:,1:200];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type RBM_col{T <: Real}\n",
    "    W::Matrix{T}         \n",
    "    vis_bias::Vector{T}     \n",
    "    hid_bias::Vector{T}   \n",
    "    n_vis::Int64\n",
    "    n_hid::Int64\n",
    "    trained::Bool\n",
    "end\n",
    "\n",
    "\n",
    "function initializeRBM_col(n_vis::Int64, n_hid::Int64; sigma=0.01, T=Float64)\n",
    "    \n",
    "    return RBM_col{T}(sigma*randn(n_hid,n_vis),  # weight matrix\n",
    "                      zeros(n_vis),              # visible vector  \n",
    "                      zeros(n_hid),              # Hidden vector\n",
    "                      n_vis,                     # num visible units \n",
    "                      n_hid,                     # num hidden unnits\n",
    "                      false)                     # trained\n",
    "\n",
    "\n",
    "end\n",
    "\n",
    "rbm = initializeRBM_col(784, 225);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.6.0-dev.2069\n",
      "Commit ff9a949 (2017-01-13 02:17 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin13.4.0)\n",
      "  CPU: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) First implementation of my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K (generic function with 1 method)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function sigmoid(vector::Array{Float64})\n",
    "    return 1./(1 + e.^(-vector))\n",
    "end\n",
    "\n",
    "\n",
    "function contrastive_divergence_col_K(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x =  Xbatch[:,i]\n",
    "        xneg =  Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg = sigmoid( rbm.W * xneg .+ rbm.hid_bias) .> rand(rbm.n_hid)\n",
    "            xneg = sigmoid( rbm.W' * hneg .+ rbm.vis_bias) .> rand(rbm.n_vis)\n",
    "        end\n",
    "\n",
    "        ehp = sigmoid(rbm.W * x + rbm.hid_bias)\n",
    "        ehn = sigmoid(rbm.W * xneg + rbm.hid_bias)\n",
    " \n",
    "        ### kron vs no kron???\n",
    "        #Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_W .+= lr * ( x * ehp' - xneg * ehn')'\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contrastive_divergence_col_K(X_batch_col[:,1:10], rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.977352 seconds (18.21 k allocations: 1.342 GB, 28.73% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After 5) I realized most of the speed problem came from a transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_ (generic function with 1 method)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function sigmoid(vector::Array{Float64})\n",
    "    return 1./(1 + e.^(-vector))\n",
    "end\n",
    "\n",
    "\n",
    "function contrastive_divergence_col_K_(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x =  Xbatch[:,i]\n",
    "        xneg =  Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg = sigmoid( rbm.W * xneg .+ rbm.hid_bias) .> rand(rbm.n_hid)\n",
    "            xneg = sigmoid( rbm.W' * hneg .+ rbm.vis_bias) .> rand(rbm.n_vis)\n",
    "        end\n",
    "\n",
    "        ehp = sigmoid(rbm.W * x + rbm.hid_bias)\n",
    "        ehn = sigmoid(rbm.W * xneg + rbm.hid_bias)\n",
    " \n",
    "        ### kron vs no kron???\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrastive_divergence_col_K_(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.252066 seconds (12.61 k allocations: 28.984 MB, 1.17% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Define all vectors used inside the function and \"fill them\"\n",
    "\n",
    "Don't get why this version requires more gc time but then it has less allocation and it is a bit faster\n",
    "\n",
    "This version uses the **```similar```** function to generate the arrays beforehand and fill them later.\n",
    "\n",
    "- **B = ```similar(A)```** will generate a new array ```B``` of the same type and shape as ```A```.\n",
    "\n",
    "- We could just do  **```B = zeros(A)```** which would generate new array ```B``` of the same type and shape as ```A``` full of zeros.\n",
    "    - Notice that if A is an array then **``` zeros(A) == zeros(size(A))```** because if the input of zeros is an Array then it generates a new array of the shape of its input, if it is a tuple it generates an array of of shape equal to the tuple.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros(rbm.W) == zeros(size(rbm.W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_1 (generic function with 1 method)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contrastive_divergence_col_K_1(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(rbm.W)\n",
    "    Delta_b = zeros(rbm.vis_bias)\n",
    "    Delta_c = zeros(rbm.hid_bias)\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(rbm.vis_bias)\n",
    "    x = similar(rbm.vis_bias)\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x = Xbatch[:,i]\n",
    "        xneg = Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid( rbm.W * xneg .+ rbm.hid_bias) .> rand(rbm.n_hid)\n",
    "            xneg .= sigmoid( rbm.W' * hneg .+ rbm.vis_bias) .> rand(rbm.n_vis)\n",
    "        end\n",
    "\n",
    "        ehp .= sigmoid(rbm.W * x + rbm.hid_bias)\n",
    "        ehn .= sigmoid(rbm.W * xneg + rbm.hid_bias)\n",
    " \n",
    "        ### kron vs no kron???\n",
    "        Delta_W .+= lr * ( x * ehp' - xneg * ehn')'\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rbm = initializeRBM_col(784, 225)\n",
    "contrastive_divergence_col_K_1(X_batch_col[:,1:10], rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.421306 seconds (297.66 k allocations: 1.348 GB, 10.64% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.744455 seconds (14.02 k allocations: 1.339 GB, 21.13% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_1(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Use view in order no to copy the current instance of the minibatch\n",
    "\n",
    "We will use a view of ```Xbatch[:,i]``` instead of allocating it to x.\n",
    "\n",
    "I though that slices of arrays where passed as views not as copies...\n",
    "\n",
    "Performance decreases ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "@view A[inds...]\n",
       "```\n",
       "\n",
       "Creates a `SubArray` from an indexing expression. This can only be applied directly to a reference expression (e.g. `@view A[1,2:end]`), and should *not* be used as the target of an assignment (e.g. `@view(A[1,2:end]) = ...`).\n"
      ],
      "text/plain": [
       "```\n",
       "@view A[inds...]\n",
       "```\n",
       "\n",
       "Creates a `SubArray` from an indexing expression. This can only be applied directly to a reference expression (e.g. `@view A[1,2:end]`), and should *not* be used as the target of an assignment (e.g. `@view(A[1,2:end]) = ...`).\n"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_2 (generic function with 1 method)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contrastive_divergence_col_K_2(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(rbm.W)\n",
    "    Delta_b = zeros(rbm.vis_bias)\n",
    "    Delta_c = zeros(rbm.hid_bias)\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(rbm.vis_bias)\n",
    "    x = similar(rbm.vis_bias)\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x = @view Xbatch[:,i]\n",
    "        xneg = @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid( rbm.W * xneg .+ rbm.hid_bias) .> rand(rbm.n_hid)\n",
    "            xneg .= sigmoid( rbm.W' * hneg .+ rbm.vis_bias) .> rand(rbm.n_vis)\n",
    "        end\n",
    "\n",
    "        ehp .= sigmoid(rbm.W * Xbatch[:,i] + rbm.hid_bias)\n",
    "        ehn .= sigmoid(rbm.W * xneg + rbm.hid_bias)\n",
    " \n",
    "        ### kron vs no kron???\n",
    "        Delta_W .+= lr * (Xbatch[:,i] * ehp' - xneg * ehn')'\n",
    "        Delta_b .+= lr * (Xbatch[:,i] - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# warmup \n",
    "contrastive_divergence_col_K_2(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.721602 seconds (14.02 k allocations: 1.339 GB, 21.10% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_1(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.799129 seconds (15.82 k allocations: 1.340 GB, 18.49% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_2(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Elementwise application of the sigmoid\n",
    "\n",
    "Notice that you can apply a function f that takes as input Float64 to every position of an array of Float64 using a dot. I do not see any benefit though in terms of speed, though is more efficient in terms of KB memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(x::Float64)\n",
    "    return 2*x+23 -x^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(x::Array{Float64})\n",
    "    return 2x + 23 - x.^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = rand(10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000138 seconds (29 allocations: 79.359 KB)\n"
     ]
    }
   ],
   "source": [
    "f.(a)\n",
    "@time f.(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000036 seconds (12 allocations: 312.969 KB)\n"
     ]
    }
   ],
   "source": [
    "f(a)\n",
    "@time f(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_3 (generic function with 1 method)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Float64) = 1. / (1. + exp(-x))\n",
    "\n",
    "function contrastive_divergence_col_K_3(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(rbm.W)\n",
    "    Delta_b = zeros(rbm.vis_bias)\n",
    "    Delta_c = zeros(rbm.hid_bias)\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(rbm.vis_bias)\n",
    "    x = similar(rbm.vis_bias)\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x = Xbatch[:,i]\n",
    "        xneg = Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid.(rbm.W * xneg .+ rbm.hid_bias) .> rand()\n",
    "            xneg .= sigmoid.(rbm.W' * hneg .+ rbm.vis_bias) .> rand()\n",
    "        end\n",
    "\n",
    "        ehp .= sigmoid.(rbm.W * x + rbm.hid_bias)\n",
    "        ehn .= sigmoid.(rbm.W * xneg + rbm.hid_bias)\n",
    " \n",
    "        ### kron vs no kron???\n",
    "        Delta_W .+= lr * (x * ehp' - xneg * ehn')'\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#warmup\n",
    "contrastive_divergence_col_K_3(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.733203 seconds (14.02 k allocations: 1.339 GB, 20.99% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_1(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.728931 seconds (10.02 k allocations: 1.327 GB, 21.26% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_3(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Using the BLAS\n",
    "\n",
    "Using A_mul_B! is not in itself enough to speed up the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_4 (generic function with 1 method)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Float64) = 1. / (1. + exp(-x))\n",
    "\n",
    "function contrastive_divergence_col_K_4(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(rbm.W)\n",
    "    Delta_b = zeros(rbm.vis_bias)\n",
    "    Delta_c = zeros(rbm.hid_bias)\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(rbm.vis_bias)\n",
    "    x = similar(rbm.vis_bias)\n",
    "    b1 = similar(rbm.hid_bias)\n",
    "    b2 = similar(rbm.vis_bias)\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x = Xbatch[:,i]\n",
    "        xneg = Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            A_mul_B!(b1, rbm.W, xneg)\n",
    "            hneg .= sigmoid.(b1 .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid.(b2 .+ rbm.vis_bias) .> rand.()\n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "        \n",
    "        ### kron vs no kron???\n",
    "        \n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "\n",
    "        #Delta_W .+= lr * (x * ehp' - xneg * ehn')'\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " contrastive_divergence_col_K_4(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.172969 seconds (2.82 k allocations: 10.858 MB, 2.46% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_4(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5)    Do not need transpose!!  Delta_W .+= lr * ( x * ehp' - xneg * ehn')'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sigmoid(x::Float64) = 1. / (1. + exp(-x))\n",
    "\n",
    "function contrastive_divergence_col_K_5(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(rbm.W)\n",
    "    Delta_b = zeros(rbm.vis_bias)\n",
    "    Delta_c = zeros(rbm.hid_bias)\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(rbm.vis_bias)\n",
    "    x = similar(rbm.vis_bias)\n",
    "    b1 = similar(rbm.hid_bias)\n",
    "    b2 = similar(rbm.vis_bias)\n",
    "    \n",
    "    for i in 1:batch_size\n",
    "        x = @view Xbatch[:,i]\n",
    "        xneg .= @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            A_mul_B!(b1, rbm.W, xneg)\n",
    "            hneg .= sigmoid.(b1 .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid.(b2 .+ rbm.vis_bias) .> rand.()\n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "    \n",
    "        # THIS IS WHAT I HAD\n",
    "        #Delta_W .+= lr * (x * ehp' - xneg * ehn')'\n",
    "        \n",
    "        #Evilzero version\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr * (x - xneg)\n",
    "        Delta_c .+= lr * (ehp - ehn)\n",
    "    end\n",
    "        \n",
    "\n",
    "    rbm.W .+= Delta_W / batch_size;\n",
    "    rbm.vis_bias .+= Delta_b / batch_size;\n",
    "    rbm.hid_bias .+= Delta_c / batch_size;\n",
    "    \n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrastive_divergence_col_K_5(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.135139 seconds (2.22 k allocations: 8.420 MB)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_5(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version which is very similar to the first one at the top of the notebook is almost as fast as evilzero version\n",
    "\n",
    "- Seems Julia really doesn't like transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evilzero version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: x not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: x not defined\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "    Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_evilzero (generic function with 1 method)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Float64) = 1. / (1. + exp(-x))\n",
    "\n",
    "\n",
    "function contrastive_divergence_col_K_evilzero(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "\n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    b1 = similar(rbm.W * Xbatch[:,1])\n",
    "    b2 = similar(rbm.W' * hneg)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(Xbatch[:,1])\n",
    "    \n",
    "    @inbounds for i in 1:batch_size\n",
    "        x = @view Xbatch[:,i]\n",
    "        xneg .= @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            A_mul_B!(b1, rbm.W, xneg)\n",
    "            hneg .= sigmoid.(b1 .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid.(b2 .+ rbm.vis_bias) .> rand.()\n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_b ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_c ./ batch_size;\n",
    "\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#warmup\n",
    "contrastive_divergence_col_K_evilzero(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.131786 seconds (1.42 k allocations: 3.863 MB)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@time contrastive_divergence_col_K_evilzero(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A trivial improvement: We know the shape of b1 and b2 beforehand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_col_K_evilzero_1 (generic function with 1 method)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x::Float64) = 1. / (1. + exp(-x))\n",
    "\n",
    "\n",
    "function contrastive_divergence_col_K_evilzero_1(Xbatch, rbm, K::Int64, lr::Float64)\n",
    "\n",
    "    batch_size = size(Xbatch)[2]\n",
    "\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    b1 = similar(rbm.W * Xbatch[:,1])\n",
    "    b2 = similar(rbm.W' * hneg)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "    xneg = similar(Xbatch[:,1])\n",
    "    \n",
    "    @inbounds for i in 1:batch_size\n",
    "        x = @view Xbatch[:,i]\n",
    "        xneg .= @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            A_mul_B!(b1, rbm.W, xneg)\n",
    "            hneg .= sigmoid.(b1 .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid.(b2 .+ rbm.vis_bias) .> rand.()\n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid.(b1 .+ rbm.hid_bias)\n",
    "\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_b ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_c ./ batch_size;\n",
    "\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contrastive_divergence_col_K_evilzero_1(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.134424 seconds (1.42 k allocations: 3.863 MB)\n"
     ]
    }
   ],
   "source": [
    "@time contrastive_divergence_col_K_evilzero_1(X_batch_col, rbm, 1, 0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-dev",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
