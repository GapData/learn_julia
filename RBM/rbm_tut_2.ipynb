{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM implementation\n",
    "\n",
    "Objective: Implement CRBM in Julia for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Distributions to generate random numbers W matrix of the RBM\n",
    "using Distributions\n",
    "using MNIST\n",
    "using BenchmarkTools\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type RBM{T <: Real}\n",
    "    n_vis::Int\n",
    "    n_hid::Int\n",
    "    W::Matrix{T}         \n",
    "    vis_bias::Vector{T}     \n",
    "    hid_bias::Vector{T}   \n",
    "    trained::Bool\n",
    "end\n",
    "\n",
    "function Base.show{T}(io::IO, rbm::RBM{T})\n",
    "    n_vis = size(rbm.vis_bias, 1)\n",
    "    n_hid = size(rbm.hid_bias, 1)\n",
    "    trained = rbm.trained\n",
    "    print(io, \"RBM{$T}(n_vis=$n_vis, n_hid=$n_hid, trained=$trained)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(vector::Array{Float64})\n",
    "    return 1./(1 + exp.(-vector))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 2 methods)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(x::Float64)\n",
    "    return 1/(1 + exp(-x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_RBM (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_RBM(n_vis, n_hid, sigma, T)\n",
    "    \n",
    "    return RBM{T}( n_vis,                                 # num visible units \n",
    "                   n_hid,                                 # num hidden unnits\n",
    "                   rand(Normal(0,sigma), n_hid, n_vis),   # weight matrix\n",
    "                   zeros(n_vis),                          # visible vector  \n",
    "                   zeros(n_hid),                          # Hidden vector\n",
    "                   false)                                 # trained\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM{Float64}(n_vis=784, n_hid=100, trained=false)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = initialize_RBM(784, 100, 0.01, Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(rbm.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "[7.0,2.0,1.0,0.0,4.0,1.0,4.0,9.0,5.0,9.0  …  7.0,8.0,9.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = MNIST.traindata()\n",
    "X_test, y_test = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "    \n",
    "    xneg = zeros(size(rbm.vis_bias))\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    b1 = similar(rbm.W * Xbatch[:,1])\n",
    "    b2 = similar(rbm.W' * hneg)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "        \n",
    "    @inbounds for i in 1:batch_size\n",
    "        x =  @view Xbatch[:,i]\n",
    "        xneg = @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid(rbm.W * xneg .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid(b2 .+ rbm.vis_bias) .> rand.()         \n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_b ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_c ./ batch_size;\n",
    "\n",
    "    return \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "\n",
    "@benchmark contrastive_divergence_K(X_batch, rbm, 1, 0.01)\n",
    "#@time contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size(X_train), size(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    print(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "            \n",
    "        end\n",
    "        print(\"\\nepoch \", epoch, \"  time epoch:\", toq())\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PyPlot.imshow(reshape(rbm.W[9,:],28,28),\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 200\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vectorized cdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg = sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        #print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_greys = PyPlot.cm_get_cmap(\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PyPlot.imshow(reshape(rbm.W[9,:],28,28),cm_greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshape(rbm.W[9,:],28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE arrays at the beginning of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand(:(lr.*( Ehp * Xbatch' .-  Ehn *  Xneg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?A_mul_Bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand(:(rbm.W * Xbatch .+ rbm.hid_bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = Xbatch\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid.(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid.(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid.(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid.(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr.*( Ehp * Xbatch' .-  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp .- Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 3, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define space for all the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "    \n",
    "    rbm.W .+= lr.*( Ehp * Xbatch' .-  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp .- Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    #println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        #print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 500\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@benchmark vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the BLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.ger!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The blas has understandable names in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?A_mul_Bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?At_mul_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?A_mul_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Hneg= rand(rbm.n_hid, batch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(rbm.W' * Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "At_mul_B(rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand(:(rbm.W' * Hneg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@benchmark Ac_mul_B(rbm.W,Hneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@benchmark At_mul_B(rbm.W,Hneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        #Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Hneg .= sigmoid.(A_mul_B(Rbm.W,Xneg) .+ rbm.hid_bias) .> rand()\n",
    "        #Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "        Xneg .= sigmoid.(At_mul_B(rbm.W, Hneg) .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid.( A_mul_B(rbm.W, Xbatch) .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid.( A_mul_B(rbm.W, Xneg) .+ rbm.hid_bias)\n",
    "   \n",
    "    #rbm.W .+= lr*( Ehp * Xbatch' -  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.W .+= lr.*(A_mul_Bt(Ehp, Xbatch) .- A_mul_Bt(Ehn, Xneg)) ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp .- Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 500\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@benchmark vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allocating memory inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real, Hneg, Xneg, Ehp,Ehn  )\n",
    "    \n",
    "    Xneg = Xbatch\n",
    "\n",
    "    for k in 1:K\n",
    "        #Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Hneg .= sigmoid( rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        #Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "        Xneg .= sigmoid(At_mul_B(rbm.W, Hneg) .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "   \n",
    "    #rbm.W .+= lr*( Ehp * Xbatch' -  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.W .+= lr.*(A_mul_Bt(Ehp, Xbatch) .- A_mul_Bt(Ehn, Xneg)) ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp - Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function mem_vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    \n",
    "    batch_size = length(indicies[1] )\n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Hneg .= zero(Hneg)\n",
    "            Xneg .= zero(Xneg)\n",
    "            Ehp .= zero(Ehp)\n",
    "            Ehn .= zero(Ehn)\n",
    "            \n",
    "            vec_contrastive_divergence_K(X[:, minibatch_ind], rbm, K, lr, Hneg, Xneg, Ehp,Ehn  )\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@benchmark mem_vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Optimized vectorial\n",
    "\n",
    "Use BLAS directly to make the \"transposes\"\n",
    "\n",
    "- https://discourse.julialang.org/t/blas-performance-issues-for-common-neural-network-patterns/565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xbatch = X_train[:,1:25]\n",
    "Xneg = copy(Xbatch)\n",
    "Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?BLAS.gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(rbm.W' * Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@benchmark rbm.W' * Hneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@benchmark BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[3,4,5] .> rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = Float32\n",
    "function optvec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    # I put the line below here because then \n",
    "    # Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand() \n",
    "    # is cast as an Array{float64} and then I can use the BLAS \n",
    "    # without errors\n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "\n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid(BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark optvec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expand(:(Delta_W .+= lr * ( x * ehp' - xneg * ehn')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?A_mul_Bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0-dev",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
