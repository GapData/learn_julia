{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM and CRBM\n",
    "\n",
    "Objective: Implement CRBM in Julia for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Distributions to generate the W matrix of the RBM\n",
    "using Distributions\n",
    "using MNIST\n",
    "#using BenchmarkTools\n",
    "using Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type RBM{T <: Real}\n",
    "    n_vis::Int\n",
    "    n_hid::Int\n",
    "    W::Matrix{T}         \n",
    "    vis_bias::Vector{T}     \n",
    "    hid_bias::Vector{T}   \n",
    "    trained::Bool\n",
    "end\n",
    "\n",
    "function Base.show{T}(io::IO, rbm::RBM{T})\n",
    "    n_vis = size(rbm.vis_bias, 1)\n",
    "    n_hid = size(rbm.hid_bias, 1)\n",
    "    trained = rbm.trained\n",
    "    print(io, \"RBM{$T}(n_vis=$n_vis, n_hid=$n_hid, trained=$trained)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(vector::Array{Float64})\n",
    "    return 1./(1 + exp(-vector))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_RBM (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_RBM(n_vis, n_hid, sigma, T)\n",
    "    \n",
    "    return RBM{T}( n_vis,                                 # num visible units \n",
    "                   n_hid,                                 # num hidden unnits\n",
    "                   rand(Normal(0,sigma), n_hid, n_vis),  # weight matrix\n",
    "                   zeros(n_vis),                          # visible vector  \n",
    "                   zeros(n_hid),                          # Hidden vector\n",
    "                   false)                                 # trained\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM{Float64}(n_vis=784, n_hid=100, trained=false)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = initialize_RBM(784, 100, 0.01, Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(rbm.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "[7.0,2.0,1.0,0.0,4.0,1.0,4.0,9.0,5.0,9.0  …  7.0,8.0,9.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = MNIST.traindata()\n",
    "X_test, y_test = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "    \n",
    "    xneg = zeros(size(rbm.vis_bias))\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    b1 = similar(rbm.W * Xbatch[:,1])\n",
    "    b2 = similar(rbm.W' * hneg)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "        \n",
    "    @inbounds for i in 1:batch_size\n",
    "        x =  @view Xbatch[:,i]\n",
    "        xneg = @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid(rbm.W * xneg .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid(b2 .+ rbm.vis_bias) .> rand.()         \n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_b ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_c ./ batch_size;\n",
    "\n",
    "    return \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 40.97 ms [26.44 ms, 55.49 ms]\n",
       "Proportion of time in GC: 6.99% [2.83%, 11.16%]\n",
       "        Memory allocated: 78.83 mb\n",
       "   Number of allocations: 3594 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 5.30 s\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "\n",
    "@benchmark contrastive_divergence_K(X_batch, rbm, 1, 0.01)\n",
    "#@time contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,60000),(784,25))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_train), size(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    print(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "            \n",
    "        end\n",
    "        print(\"\\nepoch \", epoch, \"  time epoch:\", toq())\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:300\n",
      "\n",
      "epoch 1  time epoch:107.746640715108.065719 seconds (8.71 M allocations: 180.974 GB, 6.64% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 200\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vectorized cdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg = sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid( rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 21.38 ms [18.65 ms, 24.10 ms]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 5.36 mb\n",
       "   Number of allocations: 173 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 4.74 s\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec_fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:60\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:31.606272515\n",
      " 33.093533 seconds (2.10 M allocations: 4.316 GB, 1.17% gc time)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VERY IMPORTANT: DEFINE VARIABLES AT THE BEGINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition vec_contrastive_divergence_K(Any, Any, Integer, Real) in module Main at In[13]:3 overwritten at In[17]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 4.58 ms [3.55 ms, 5.60 ms]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 5.53 mb\n",
       "   Number of allocations: 175 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 0.93 s\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition vec_fit_CDK(Any, Any, Integer, Integer, Integer, Real) in module Main at In[15]:3 overwritten at In[19]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vec_fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:60\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:8.467765761\n",
      "  8.469279 seconds (49.26 k allocations: 4.664 GB, 39.08% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define space for all the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition vec_contrastive_divergence_K(Any, Any, Integer, Real) in module Main at In[59]:3 overwritten at In[62]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "   \n",
    "    rbm.W .+= lr*( Ehp * Xbatch' -  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp - Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 6.60 ms [2.71 ms, 10.50 ms]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 5.57 mb\n",
       "   Number of allocations: 179 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 1.43 s\n"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:60\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:7.035202554\n",
      "  7.049922 seconds (49.49 k allocations: 4.664 GB, 21.55% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the BLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemm(tA, tB, alpha, A, B)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n",
       "\n",
       "```\n",
       "gemm(tA, tB, A, B)\n",
       "```\n",
       "\n",
       "Returns `A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemm(tA, tB, alpha, A, B)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n",
       "\n",
       "```\n",
       "gemm(tA, tB, A, B)\n",
       "```\n",
       "\n",
       "Returns `A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemm!(tA, tB, alpha, A, B, beta, C)\n",
       "```\n",
       "\n",
       "Update `C` as `alpha*A*B + beta*C` or the other three variants according to `tA` (transpose `A`) and `tB`. Returns the updated `C`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemm!(tA, tB, alpha, A, B, beta, C)\n",
       "```\n",
       "\n",
       "Update `C` as `alpha*A*B + beta*C` or the other three variants according to `tA` (transpose `A`) and `tB`. Returns the updated `C`.\n"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemv!(tA, alpha, A, x, beta, y)\n",
       "```\n",
       "\n",
       "Update the vector `y` as `alpha*A*x + beta*y` or `alpha*A'x + beta*y` according to `tA` (transpose `A`). Returns the updated `y`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemv!(tA, alpha, A, x, beta, y)\n",
       "```\n",
       "\n",
       "Update the vector `y` as `alpha*A*x + beta*y` or `alpha*A'x + beta*y` according to `tA` (transpose `A`). Returns the updated `y`.\n"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "ger!(alpha, x, y, A)\n",
       "```\n",
       "\n",
       "Rank-1 update of the matrix `A` with vectors `x` and `y` as `alpha*x*y' + A`.\n"
      ],
      "text/plain": [
       "```\n",
       "ger!(alpha, x, y, A)\n",
       "```\n",
       "\n",
       "Rank-1 update of the matrix `A` with vectors `x` and `y` as `alpha*x*y' + A`.\n"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.ger!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The blas has understandable names in Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mt\u001b[22m \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mt\u001b[22m! \u001b[1mA\u001b[22mt\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mt\u001b[22m \u001b[1mA\u001b[22mt\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mt\u001b[22m! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mc \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mc!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "A_mul_Bt(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $A⋅Bᵀ$.\n"
      ],
      "text/plain": [
       "```\n",
       "A_mul_Bt(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $A⋅Bᵀ$.\n"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?A_mul_Bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mA\u001b[22m\u001b[1mt\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m \u001b[1mA\u001b[22m\u001b[1mt\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt \u001b[1mA\u001b[22m\u001b[1mt\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m! \u001b[1mA\u001b[22m\u001b[1mt\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "At_mul_B(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $Aᵀ⋅B$.\n"
      ],
      "text/plain": [
       "```\n",
       "At_mul_B(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $Aᵀ⋅B$.\n"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?At_mul_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mc \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mc! \u001b[1mA\u001b[22mt\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m \u001b[1mA\u001b[22mc\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\n",
      "\n",
      "Couldn't find \u001b[36mA_mul_B\n",
      "\u001b[39mPerhaps you meant A_mul_B!, A_mul_Bc, A_mul_Bt, Ac_mul_B, At_mul_B or A_mul_Bc!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "Binding `A_mul_B` does not exist.\n"
      ],
      "text/plain": [
       "No documentation found.\n",
       "\n",
       "Binding `A_mul_B` does not exist.\n"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?A_mul_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.0766849\n",
       " -0.0577609\n",
       " -0.106906 "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rbm.W' * Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.0766849\n",
       " -0.0577609\n",
       " -0.106906 "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.0766849\n",
       " -0.0577609\n",
       " -0.106906 "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "At_mul_B(rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition vec_contrastive_divergence_K(Any, Any, Integer, Real) in module Main at In[71]:3 overwritten at In[73]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 2 methods)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for k in 1:K\n",
    "        #Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Hneg .= sigmoid( rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        #Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "        Xneg .= sigmoid(At_mul_B(rbm.W, Hneg) .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "   \n",
    "    #rbm.W .+= lr*( Ehp * Xbatch' -  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.W .+= lr*(A_mul_Bt(Ehp, Xbatch) .- A_mul_Bt(Ehn, Xneg)) ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp - Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:150\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:5.305408089\n",
      "  5.307262 seconds (63.63 k allocations: 4.983 GB, 5.74% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 400\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allocating memory inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 2 methods)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real, Hneg, Xneg, Ehp,Ehn  )\n",
    "    \n",
    "    Xneg = Xbatch\n",
    "\n",
    "    for k in 1:K\n",
    "        #Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Hneg .= sigmoid( rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        #Xneg .= sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "        Xneg .= sigmoid(At_mul_B(rbm.W, Hneg) .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp .= sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "   \n",
    "    #rbm.W .+= lr*( Ehp * Xbatch' -  Ehn *  Xneg') ./ batch_size;\n",
    "    rbm.W .+= lr*(A_mul_Bt(Ehp, Xbatch) .- A_mul_Bt(Ehn, Xneg)) ./ batch_size;\n",
    "    rbm.vis_bias .+= sum(lr .* (Xbatch .- Xneg), 2)[:]./ batch_size;\n",
    "    rbm.hid_bias .+= sum(lr .* (Ehp - Ehn), 2)[:] ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mem_vec_fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mem_vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    \n",
    "    batch_size = length(indicies[1] )\n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "    local Ehp::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Ehn::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    \n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Hneg .= zero(Hneg)\n",
    "            Xneg .= zero(Xneg)\n",
    "            Ehp .= zero(Ehp)\n",
    "            Ehn .= zero(Ehn)\n",
    "            \n",
    "            vec_contrastive_divergence_K(X[:, minibatch_ind], rbm, K, lr, Hneg, Xneg, Ehp,Ehn  )\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:60\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:8.194700379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "Warning: function may not have been precompiled\n",
       "     Time per evaluation: 8.24 s\n",
       "Proportion of time in GC: 39.90%\n",
       "        Memory allocated: 4.76 gb\n",
       "   Number of allocations: 101515 allocations\n",
       "       Number of samples: 1\n",
       "   Number of evaluations: 1\n",
       " Time spent benchmarking: 8.61 s\n"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@benchmark mem_vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m sp\u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m non\u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m drop\u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m drop\u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m! count_\u001b[1mz\u001b[22m\u001b[1me\u001b[22m\u001b[1mr\u001b[22m\u001b[1mo\u001b[22m\u001b[1ms\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "zeros(type, dims)\n",
       "```\n",
       "\n",
       "Create an array of all zeros of specified type. The type defaults to Float64 if not specified.\n",
       "\n",
       "```\n",
       "zeros(A)\n",
       "```\n",
       "\n",
       "Create an array of all zeros with the same element type and shape as `A`.\n"
      ],
      "text/plain": [
       "```\n",
       "zeros(type, dims)\n",
       "```\n",
       "\n",
       "Create an array of all zeros of specified type. The type defaults to Float64 if not specified.\n",
       "\n",
       "```\n",
       "zeros(A)\n",
       "```\n",
       "\n",
       "Create an array of all zeros with the same element type and shape as `A`.\n"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Optimized vectorial\n",
    "\n",
    "Use BLAS directly to make the \"transposes\"\n",
    "\n",
    "- https://discourse.julialang.org/t/blas-performance-issues-for-common-neural-network-patterns/565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemv(tA, alpha, A, x)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*x` or `alpha*A'x` according to `tA` (transpose `A`).\n",
       "\n",
       "```\n",
       "gemv(tA, A, x)\n",
       "```\n",
       "\n",
       "Returns `A*x` or `A'x` according to `tA` (transpose `A`).\n"
      ],
      "text/plain": [
       "```\n",
       "gemv(tA, alpha, A, x)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*x` or `alpha*A'x` according to `tA` (transpose `A`).\n",
       "\n",
       "```\n",
       "gemv(tA, A, x)\n",
       "```\n",
       "\n",
       "Returns `A*x` or `A'x` according to `tA` (transpose `A`).\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemv!(tA, alpha, A, x, beta, y)\n",
       "```\n",
       "\n",
       "Update the vector `y` as `alpha*A*x + beta*y` or `alpha*A'x + beta*y` according to `tA` (transpose `A`). Returns the updated `y`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemv!(tA, alpha, A, x, beta, y)\n",
       "```\n",
       "\n",
       "Update the vector `y` as `alpha*A*x + beta*y` or `alpha*A'x + beta*y` according to `tA` (transpose `A`). Returns the updated `y`.\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemv!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xbatch = X_train[:,1:25]\n",
    "Xneg = copy(Xbatch)\n",
    "Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "gemm(tA, tB, alpha, A, B)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n",
       "\n",
       "```\n",
       "gemm(tA, tB, A, B)\n",
       "```\n",
       "\n",
       "Returns `A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n"
      ],
      "text/plain": [
       "```\n",
       "gemm(tA, tB, alpha, A, B)\n",
       "```\n",
       "\n",
       "Returns `alpha*A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n",
       "\n",
       "```\n",
       "gemm(tA, tB, A, B)\n",
       "```\n",
       "\n",
       "Returns `A*B` or the other three variants according to `tA` (transpose `A`) and `tB`.\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?BLAS.gemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.0100554 \n",
       " -0.00985561\n",
       " -0.0187645 "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rbm.W' * Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.0100554 \n",
       " -0.00985561\n",
       " -0.0187645 "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 190.88 μs [167.04 μs, 214.72 μs]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 153.23 kb\n",
       "   Number of allocations: 3 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 0.52 s\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark rbm.W' * Hneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 577.60 μs [0.00 ns, 1.56 ms]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 153.23 kb\n",
       "   Number of allocations: 3 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 0.62 s\n"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element BitArray{1}:\n",
       " true\n",
       " true\n",
       " true"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3,4,5] .> rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3635189487245134"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition optvec_contrastive_divergence_K(Any, Any, Integer, Real) in module Main at In[205]:4 overwritten at In[209]:4.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "optvec_contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = Float32\n",
    "function optvec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    # I put the line below here because then \n",
    "    # Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand() \n",
    "    # is cast as an Array{float64} and then I can use the BLAS \n",
    "    # without errors\n",
    "    local Hneg::Array{Float64} = zeros(rbm.n_hid, batch_size)\n",
    "    local Xneg::Array{Float64} = zeros(rbm.n_vis, batch_size)\n",
    "\n",
    "    for k in 1:K\n",
    "        Hneg .= sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg .= sigmoid(BLAS.gemm('T','N', Float64(1.0), rbm.W, Hneg)  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid(rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 7.49 ms [4.17 ms, 10.80 ms]\n",
       "Proportion of time in GC: 0.00% [0.00%, 0.00%]\n",
       "        Memory allocated: 5.53 mb\n",
       "   Number of allocations: 175 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 1.33 s\n"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark optvec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":((Base.broadcast!)(Base.identity,Delta_W,Delta_W .+ A_mul_Bc(lr,A_mul_Bc(x,ehp) - A_mul_Bc(xneg,ehn))))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand(:(Delta_W .+= lr * ( x * ehp' - xneg * ehn')'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mc\u001b[22m \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mc\u001b[22m! \u001b[1mA\u001b[22mc\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mc\u001b[22m \u001b[1mA\u001b[22mc\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m\u001b[1mc\u001b[22m! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22m! \u001b[1mA\u001b[22m\u001b[1m_\u001b[22m\u001b[1mm\u001b[22m\u001b[1mu\u001b[22m\u001b[1ml\u001b[22m\u001b[1m_\u001b[22m\u001b[1mB\u001b[22mt!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "A_mul_Bc(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $A⋅Bᴴ$.\n"
      ],
      "text/plain": [
       "```\n",
       "A_mul_Bc(A, B)\n",
       "```\n",
       "\n",
       "For matrices or vectors $A$ and $B$, calculates $A⋅Bᴴ$.\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?A_mul_Bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
