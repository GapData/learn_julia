{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBM and CRBM\n",
    "\n",
    "Objective: Implement CRBM in Julia for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Distributions to generate the W matrix of the RBM\n",
    "using Distributions\n",
    "using MNIST\n",
    "using Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type RBM{T <: Real}\n",
    "    n_vis::Int\n",
    "    n_hid::Int\n",
    "    W::Matrix{T}         \n",
    "    vis_bias::Vector{T}     \n",
    "    hid_bias::Vector{T}   \n",
    "    trained::Bool\n",
    "end\n",
    "\n",
    "function Base.show{T}(io::IO, rbm::RBM{T})\n",
    "    n_vis = size(rbm.vis_bias, 1)\n",
    "    n_hid = size(rbm.hid_bias, 1)\n",
    "    trained = rbm.trained\n",
    "    print(io, \"RBM{$T}(n_vis=$n_vis, n_hid=$n_hid, trained=$trained)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(vector::Array{Float64})\n",
    "    return 1./(1 + exp(-vector))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_RBM (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_RBM(n_vis, n_hid, sigma, T)\n",
    "    \n",
    "    return RBM{T}( n_vis,                                 # num visible units \n",
    "                   n_hid,                                 # num hidden unnits\n",
    "                   rand(Normal(0,sigma), n_hid, n_vis),  # weight matrix\n",
    "                   zeros(n_vis),                          # visible vector  \n",
    "                   zeros(n_hid),                          # Hidden vector\n",
    "                   false)                                 # trained\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM{Float64}(n_vis=784, n_hid=100, trained=false)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = initialize_RBM(784, 100, 0.01, Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(rbm.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0],\n",
       "\n",
       "[7.0,2.0,1.0,0.0,4.0,1.0,4.0,9.0,5.0,9.0  …  7.0,8.0,9.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = MNIST.traindata()\n",
    "X_test, y_test = MNIST.testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "        \n",
    "    batch_size = size(Xbatch)[2]\n",
    "    Delta_W = zeros(size(rbm.W))\n",
    "    Delta_b = zeros(size(rbm.vis_bias))\n",
    "    Delta_c = zeros(size(rbm.hid_bias))\n",
    "    \n",
    "    xneg = zeros(size(rbm.vis_bias))\n",
    "    hneg = similar(rbm.hid_bias)\n",
    "    b1 = similar(rbm.W * Xbatch[:,1])\n",
    "    b2 = similar(rbm.W' * hneg)\n",
    "    ehp = similar(rbm.hid_bias)\n",
    "    ehn = similar(rbm.hid_bias)\n",
    "        \n",
    "    @inbounds for i in 1:batch_size\n",
    "        x =  @view Xbatch[:,i]\n",
    "        xneg = @view Xbatch[:,i]\n",
    "\n",
    "        for k in 1:K\n",
    "            hneg .= sigmoid(rbm.W * xneg .+ rbm.hid_bias) .> rand.()\n",
    "            At_mul_B!(b2, rbm.W, hneg)\n",
    "            xneg .= sigmoid(b2 .+ rbm.vis_bias) .> rand.()         \n",
    "        end\n",
    "\n",
    "        A_mul_B!(b1, rbm.W, x)\n",
    "        ehp .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "        A_mul_B!(b1, rbm.W, xneg)\n",
    "        ehn .= sigmoid(b1 .+ rbm.hid_bias)\n",
    "\n",
    "        Delta_W .+= lr .* (ehp .* x' .- ehn .* xneg')\n",
    "        Delta_b .+= lr .* (x .- xneg)\n",
    "        Delta_c .+= lr .* (ehp .- ehn)\n",
    "\n",
    "    end\n",
    "\n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_b ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_c ./ batch_size;\n",
    "\n",
    "    return \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 27.76 ms [22.54 ms, 32.98 ms]\n",
       "Proportion of time in GC: 8.20% [3.49%, 12.91%]\n",
       "        Memory allocated: 78.83 mb\n",
       "   Number of allocations: 3594 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 3.90 s\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "\n",
    "@benchmark contrastive_divergence_K(X_batch, rbm, 1, 0.01)\n",
    "#@time contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,60000),(784,25))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(X_train), size(X_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    print(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "            \n",
    "        end\n",
    "        print(\"\\nepoch \", epoch, \"  time epoch:\", toq())\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:300\n",
      "\n",
      "epoch 1  time epoch:109.878847006110.166125 seconds (8.71 M allocations: 180.974 GB, 6.15% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 200\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# vectorized cdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition vec_contrastive_divergence_K(Any, Any, Integer, Real) in module Main at In[21]:3 overwritten at In[32]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vec_contrastive_divergence_K (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_contrastive_divergence_K(Xbatch, rbm, K::Integer, lr::Real)\n",
    "    \n",
    "    Xneg = copy(Xbatch)\n",
    "    batch_size = size(Xbatch)[2]\n",
    "    \n",
    "    for k in 1:K\n",
    "        Hneg = sigmoid(rbm.W * Xneg .+ rbm.hid_bias) .> rand()\n",
    "        Xneg = sigmoid(rbm.W' * Hneg  .+ rbm.vis_bias) .> rand()\n",
    "    end\n",
    "       \n",
    "    Ehp = sigmoid(rbm.W * Xbatch .+ rbm.hid_bias)\n",
    "    Ehn = sigmoid( rbm.W * Xneg .+ rbm.hid_bias)\n",
    "\n",
    "    Delta_W = lr*( Ehp * Xbatch' -  Ehn *  Xneg')\n",
    "    Delta_vis_bias = sum(lr .* (Xbatch .- Xneg), 2)[:]\n",
    "    Delta_hid_bias = sum(lr .* (Ehp - Ehn), 2)[:]\n",
    "    \n",
    "    rbm.W .+= Delta_W ./ batch_size;\n",
    "    rbm.vis_bias .+= Delta_vis_bias ./ batch_size;\n",
    "    rbm.hid_bias .+= Delta_hid_bias ./ batch_size;\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================ Benchmark Results ========================\n",
       "     Time per evaluation: 26.25 ms [20.48 ms, 32.02 ms]\n",
       "Proportion of time in GC: 0.64% [0.00%, 1.36%]\n",
       "        Memory allocated: 5.36 mb\n",
       "   Number of allocations: 173 allocations\n",
       "       Number of samples: 100\n",
       "   Number of evaluations: 100\n",
       " Time spent benchmarking: 2.97 s\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch = X_train[:,1:25]\n",
    "@benchmark vec_contrastive_divergence_K(X_batch, rbm, 1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec_fit_CDK (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vec_fit_CDK(X, rbm, batch_size::Integer,  n_epochs::Integer, K::Integer, lr::Real)\n",
    "        \n",
    "    n_samples = size(X)[2]\n",
    "    indicies = [x:min(x + batch_size-1, n_samples) for x in 1:batch_size:n_samples]\n",
    "    mb = 1\n",
    "    println(\"number minibatches:\", length(indicies), \"\\n\")\n",
    "    for epoch in 1:n_epochs\n",
    "        tic();\n",
    "        for minibatch_ind in indicies\n",
    "            Xbatch = @view X[:, minibatch_ind]\n",
    "            vec_contrastive_divergence_K(Xbatch, rbm, K, lr)\n",
    "        end\n",
    "        print(\"\\n\\nepoch \", epoch, \"  time epoch:\", toq(), \"\\n\")\n",
    "    end\n",
    "    rbm.trained = true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number minibatches:30\n",
      "\n",
      "\n",
      "\n",
      "epoch 1  time epoch:29.837511542\n",
      " 29.838367 seconds (44.19 k allocations: 4.163 GB, 6.65% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 1000\n",
    "K = 1\n",
    "lr = 0.01\n",
    "\n",
    "@time vec_fit_CDK(X_train, rbm, batch_size,  n_epochs, K, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
