{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important types for sequences\n",
    "\n",
    "During the sequence tutorials we will mostly work using sequences of words. \n",
    "\n",
    "It might be useful then to define a type that will be used in the different assignemnts that you will have to face.\n",
    "\n",
    "\n",
    "Nice material:\n",
    "- http://www.nowozin.net/sebastian/blog/streaming-log-sum-exp-computation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Main.Sequence})(Any) in module Main at In[15]:6 overwritten at In[19]:6.\n",
      "WARNING: Method definition (::Type{Main.Sequence})(Any, Any) in module Main at In[15]:11 overwritten at In[19]:11.\n"
     ]
    }
   ],
   "source": [
    "type Sequence\n",
    "    words::Array{String}\n",
    "    labels::Array{String}\n",
    "    \n",
    "    function Sequence(words)\n",
    "        states=[\"*\" for x in words]\n",
    "        return new(words, states)\n",
    "    end\n",
    "    \n",
    "    function Sequence(words, states)\n",
    "        return new(words, states)\n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[],String[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequence([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition length(Main.Sequence) in module Main at In[17]:2 overwritten at In[21]:2.\n"
     ]
    }
   ],
   "source": [
    "function Base.length(sequence::Sequence)\n",
    "    return length(sequence.words)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"the\",\"house\",\"is\",\"big\"],String[\"*\",\"*\",\"*\",\"*\"])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = Sequence([\"the\", \"house\", \"is\", \"big\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(seq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"*\"\n",
       " \"*\"\n",
       " \"*\"\n",
       " \"*\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(seq1.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"the\",\"house\",\"is\",\"big\"],String[\"*\",\"*\",\"*\",\"*\"])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a sequence of words with a sequence of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"the\",\"house\",\"is\",\"big\"],String[\"det\",\"noun\",\"verb\",\"adj\"])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2 = Sequence([\"the\", \"house\", \"is\", \"big\"],\n",
    "                [\"det\",\"noun\",\"verb\",\"adj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"det\" \n",
       " \"noun\"\n",
       " \"verb\"\n",
       " \"adj\" "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"the\",\"house\",\"is\",\"big\"],String[\"det\",\"noun\",\"verb\",\"adj\"])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = Sequence([\"the\", \"house\", \"is\", \"big\"], \n",
    "               [\"det\",\"noun\",\"verb\",\"adj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{String,1}:\n",
       " \"det\" \n",
       " \"noun\"\n",
       " \"verb\"\n",
       " \"adj\" "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be carefull with phrases!\n",
    "\n",
    "- **The type that we just defined does not accept single strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: Cannot `convert` an object of type String to an object of type Array{String,N}\nThis may have arisen from a call to the constructor Array{String,N}(...),\nsince type constructors fall back to convert methods.",
     "output_type": "error",
     "traceback": [
      "MethodError: Cannot `convert` an object of type String to an object of type Array{String,N}\nThis may have arisen from a call to the constructor Array{String,N}(...),\nsince type constructors fall back to convert methods.",
      "",
      " in Sequence(::String) at ./In[19]:7"
     ]
    }
   ],
   "source": [
    "Sequence(\"the house is big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nevertheless the ```sequence``` type can accept an Array with a single string containing a sequence. **\n",
    "\n",
    "**This is a behaviour we might not want it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"the house is big\"],String[\"*\"])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2 = Sequence([\"the house is big\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"the house is big\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{SubString{String},1}:\n",
       " \"the\"  \n",
       " \"house\"\n",
       " \"is\"   \n",
       " \"big\"  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(\"the house is big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{SubString{String},1}:\n",
       " \"the\"  \n",
       " \"house\"\n",
       " \"is\"   \n",
       " \"big\"  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(\"the house is big\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our toy data: Rainy/Sunny example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sigma = [\"walk\", \"shop\", \"clean\", \"tennis\"]\n",
    "Lambda = [\"rainy\", \"sunny\"]\n",
    "\n",
    "sequence_list = []\n",
    "\n",
    "s1 = Sequence([\"walk\", \"walk\", \"shop\", \"clean\"],\n",
    "             [\"rainy\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "s2 = Sequence([\"walk\", \"walk\", \"shop\", \"clean\"], \n",
    "              [\"rainy\", \"rainy\", \"rainy\", \"sunny\"])\n",
    "\n",
    "s3 = Sequence([\"walk\", \"shop\", \"shop\", \"clean\"], \n",
    "              [\"sunny\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "train_sequences = [s1, s2, s3]\n",
    "\n",
    "s1_t = Sequence([\"walk\", \"walk\", \"shop\", \"clean\"], \n",
    "                [\"rainy\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "s2_t = Sequence([\"clean\", \"walk\", \"tennis\", \"walk\"], \n",
    "                [\"sunny\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "test_sequences = [s1_t, s2_t];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(String[\"walk\",\"walk\",\"shop\",\"clean\"],String[\"rainy\",\"rainy\",\"rainy\",\"sunny\"])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Sequence,1}:\n",
       " Sequence(String[\"walk\",\"walk\",\"shop\",\"clean\"],String[\"rainy\",\"sunny\",\"sunny\",\"sunny\"])\n",
       " Sequence(String[\"walk\",\"walk\",\"shop\",\"clean\"],String[\"rainy\",\"rainy\",\"rainy\",\"sunny\"])\n",
       " Sequence(String[\"walk\",\"shop\",\"shop\",\"clean\"],String[\"sunny\",\"sunny\",\"sunny\",\"sunny\"])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Sequence,1}:\n",
       " Sequence(String[\"walk\",\"walk\",\"shop\",\"clean\"],String[\"rainy\",\"sunny\",\"sunny\",\"sunny\"])  \n",
       " Sequence(String[\"clean\",\"walk\",\"tennis\",\"walk\"],String[\"sunny\",\"sunny\",\"sunny\",\"sunny\"])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all possible states and all possible words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 0 entries"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_int = Dict{String,Int64}()\n",
    "state_to_int = Dict{String,Int64}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_possible_words_and_states (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_possible_words_and_states(sequences)\n",
    "    state_counter = 1\n",
    "    word_counter = 1\n",
    "    \n",
    "    possible_words = Set{String}()\n",
    "    possible_states = Set{String}()\n",
    "    \n",
    "    for seq in sequences\n",
    "        for (t,w) in zip(seq.labels, seq.words)\n",
    "            push!(possible_states, t)\n",
    "            push!(possible_words, w)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return possible_words, possible_states\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Set(String[\"tennis\",\"walk\",\"clean\",\"shop\"]),Set(String[\"sunny\",\"rainy\"]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_words, possible_states = get_possible_words_and_states([train_sequences; test_sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map words to positions and states to positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = length(possible_words)\n",
    "num_states = length(possible_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assign_elements_to_integers2 (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function assign_elements_to_integers(elements)\n",
    "    element_to_pos = Dict{String, Int64}()\n",
    "    for (k,e) in enumerate(elements)\n",
    "        element_to_pos[e] = k\n",
    "    end\n",
    "    return element_to_pos\n",
    "end\n",
    "\n",
    "function assign_elements_to_integers2(elements)\n",
    "    element_to_pos = Dict{String, Int64}()\n",
    "    k = 1\n",
    "    for e in elements\n",
    "        element_to_pos[e] = k\n",
    "        k +=1\n",
    "    end\n",
    "    return element_to_pos\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_to_pos = assign_elements_to_integers(possible_words);\n",
    "#state_to_pos = assign_elements_to_integers(possible_states);\n",
    "\n",
    "# Hardcode order\n",
    "word_to_pos = Dict(\"walk\"=>1, \"clean\" =>2, \"shop\"=>3, \"tennis\"=>4)\n",
    "state_to_pos = Dict(\"rainy\"=>1, \"sunny\"=> 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing  sufficient statistics (counts) of the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_final_counts! (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_initial_counts!(initial_counts, seq, state_to_pos)\n",
    "    initial_counts[state_to_pos[seq.labels[1]]] = initial_counts[state_to_pos[seq.labels[1]]] + 1\n",
    "end\n",
    "\n",
    "function update_transition_counts!(transition_counts, seq, state_to_pos)\n",
    "    for (t1,t2) in zip(seq.labels[1:end-1], seq.labels[2:end])\n",
    "        transition_counts[state_to_pos[t1], state_to_pos[t2]] += 1 \n",
    "    end    \n",
    "end\n",
    "\n",
    "function update_emission_counts!(emission_counts, seq, state_to_pos, word_to_pos)\n",
    "    for (t,w) in zip(seq.labels, seq.words)\n",
    "        emission_counts[state_to_pos[t], word_to_pos[w]] += 1 \n",
    "    end \n",
    "end\n",
    "\n",
    "function update_final_counts!(final_counts, seq, state_to_pos)\n",
    "    final_counts[state_to_pos[seq.labels[end]]] +=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition sufficient_statistics_hmm(Any, Any, Any) in module Main at In[47]:3 overwritten at In[113]:3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sufficient_statistics_hmm (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sufficient_statistics_hmm(sequences, state_to_pos, word_to_pos)\n",
    "    \n",
    "    n_states = length(state_to_pos)\n",
    "    n_words = length(word_to_pos)\n",
    "    \n",
    "    initial_counts      = zeros(n_states)\n",
    "    transition_counts   = zeros(n_states, n_states)\n",
    "    final_counts        = zeros(n_states)\n",
    "    emission_counts     = zeros(n_states, n_words)\n",
    "    \n",
    "    for seq in sequences\n",
    "        update_initial_counts!(initial_counts, seq, state_to_pos)\n",
    "        update_transition_counts!(transition_counts, seq,  state_to_pos)\n",
    "        update_emission_counts!(emission_counts, seq,  state_to_pos, word_to_pos)\n",
    "        update_final_counts!(final_counts, seq,  state_to_pos)\n",
    "    end\n",
    "    \n",
    "    return initial_counts, transition_counts, final_counts, emission_counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = sufficient_statistics_hmm(train_sequences, state_to_pos, word_to_pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_counts, transition_counts, final_counts, emission_counts = counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 2.0\n",
       " 1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 2.0  2.0\n",
       " 0.0  5.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.0\n",
       " 3.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 3.0  0.0  1.0  0.0\n",
       " 2.0  3.0  3.0  0.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Checks HMM\n",
    "\n",
    "- Initial counts must sum to the number of sentences  $$ \\sum_{k=1}^K C_{\\text{init}}(c_k) = M$$\n",
    "\n",
    "- Transition counts and Final Counts should sum to the number of tokens: $$\\sum_{k,l=1}^K C_{\\text{trans}}(c_k,c_l)  + \\sum_{k=1}^K C_{\\text{final}}(c_k) = M \\cdot N$$\n",
    "\n",
    "- Emission counts must sum to the number of tokens\n",
    "$$\n",
    "\\sum_{j=1}^J \\sum_{k=1}^K C_{\\text{emiss}}(w_j,c_k) = M \\cdot N \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 3.0  0.0  1.0  0.0\n",
       " 2.0  3.0  3.0  0.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 3\n",
      "N: 4\n",
      "M*N: 12"
     ]
    }
   ],
   "source": [
    "M = length(train_sequences)\n",
    "N = length(train_sequences[1].words)\n",
    "print(\"M: \", M, \"\\n\",\"N: \", N,\"\\n\" ,\"M*N: \", M*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial_counts sum: 3.0\n",
      "emission_counts sum: 12.0\n",
      "transition and final counts sum: 12.0"
     ]
    }
   ],
   "source": [
    "print(\"\\ninitial_counts sum: \", sum(initial_counts))\n",
    "print(\"\\nemission_counts sum: \", sum(emission_counts))\n",
    "print(\"\\ntransition and final counts sum: \", sum(transition_counts) + sum(final_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition check_counts(Any, Any, Any, Any, Any, Any) in module Main at In[57]:7 overwritten at In[123]:7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "check_counts (generic function with 1 method)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_counts(data, \n",
    "                      possible_states,\n",
    "                      initial_counts,\n",
    "                      transition_counts, \n",
    "                      emission_counts, \n",
    "                      final_counts)\n",
    "    \"\"\"\n",
    "    This Check is only valid if all instances have the same length!!!!\n",
    "    \"\"\"\n",
    "    n_samples = length(data)\n",
    "    sequence_length = length(data[1].words)\n",
    "    problem_checks = []\n",
    "    \n",
    "    if sum(initial_counts) != n_samples\n",
    "        print(\"\\nERROR: initial_counts are not correctly computed\")\n",
    "        push!(problem_checks,\"initial_counts\")\n",
    "    end\n",
    "    \n",
    "    if sum(transition_counts) + sum(final_counts) != sequence_length*n_samples\n",
    "        print(\"\\nERROR: transition_counts are not correctly computed\")\n",
    "        push!(problem_checks,\"transition_counts\")\n",
    "    end\n",
    "    \n",
    "    if sum(emission_counts)  != sequence_length*n_samples\n",
    "        print(\"\\nERROR: emission_counts are not correctly computed\")\n",
    "        push!(problem_checks,\"emission_counts\")\n",
    "    end\n",
    "    \n",
    "    if length(problem_checks) == 0\n",
    "        print(\"\\nAll checks passed\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All checks passed"
     ]
    }
   ],
   "source": [
    "check_counts(train_sequences, \n",
    "             possible_states,\n",
    "             initial_counts,\n",
    "             transition_counts, \n",
    "             emission_counts, \n",
    "             final_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From counts to probabilities\n",
    "\n",
    "The following formulas specify how to find the parameters of the HMM:\n",
    "\n",
    "$$\n",
    "P_{\\text{init}}(c_k \\,\\vert\\, \\text{start}) = \\frac{C_{\\text{init}}(c_k)}{ \\sum_{k=1}^K\n",
    "C_{\\text{init}} (c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{final}}(\\text{stop} \\,\\vert\\, c_l) = \\frac{C_{\\text{final}}(c_l) }\n",
    "{\\sum_{k=1}^K C_{\\text{trans}}(c_k,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{trans}}( c_k \\,\\vert\\, c_l) = \\frac{C_{\\text{trans}}(c_k, c_l) }\n",
    "{\\sum_{p=1}^K C_{\\text{trans}}(c_p,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{emiss}} (w_j \\,\\vert\\, c_k) = \\frac{C_{\\text{emiss}} (w_j, c_k) }{\\sum_{q=1}^J C_{\\text{emiss}}(w_q,c_k)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 2.0  2.0\n",
       " 0.0  5.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 0.75  0.0    0.25   0.0\n",
       " 0.25  0.375  0.375  0.0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_probs = (initial_counts / sum(initial_counts))\n",
    "transition_probs = transition_counts./(sum(transition_counts, 2) + final_counts)\n",
    "final_probs =  final_counts ./ (sum(transition_counts, 2) + final_counts )\n",
    "emission_probs = (emission_counts ./ sum(emission_counts, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Float64,1},Array{Float64,2})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(initial_counts), typeof(transition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.666667\n",
       " 0.333333"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize probabilities with the tag associated to the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 2 entries:\n",
       "  \"sunny\" => 2\n",
       "  \"rainy\" => 1"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 4 entries:\n",
       "  \"tennis\" => 4\n",
       "  \"walk\"   => 1\n",
       "  \"clean\"  => 2\n",
       "  \"shop\"   => 3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.5  0.5  \n",
       " 0.0  0.625"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 0.75  0.0    0.25   0.0\n",
       " 0.25  0.375  0.375  0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an HMM\n",
    "\n",
    "\n",
    "- Make a print function that prints beautifally the probabilities of the HMM, somehting like\n",
    "\n",
    "   hmm.transition_probs\n",
    "   \n",
    "                Sunny  Rainny\n",
    "       Sunny    0.625  0.0\n",
    "       Rainny   0.5    0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Type{Main.Hmm})() in module Main at In[67]:22 overwritten at In[133]:22.\n"
     ]
    }
   ],
   "source": [
    "type Hmm\n",
    "    possible_words::Set{String}\n",
    "    possible_states::Set{String}\n",
    "    \n",
    "    word_to_pos::Dict{String, Int64}\n",
    "    state_to_pos::Dict{String, Int64}   \n",
    "    pos_to_word::Dict{Int64, String}\n",
    "    pos_to_state::Dict{Int64, String}\n",
    "\n",
    "    initial_counts::Vector{Int64}\n",
    "    transition_counts::Matrix{Int64} \n",
    "    emission_counts::Matrix{Int64}\n",
    "    final_counts::Vector{Int64}\n",
    "\n",
    "    initial_probs::Vector{Float64}\n",
    "    transition_probs::Matrix{Float64}\n",
    "    emission_probs::Matrix{Float64}\n",
    "    final_probs::Vector{Float64}\n",
    "    \n",
    "    trained::Bool\n",
    "    \n",
    "    Hmm() = new(Set{String}(), \n",
    "                Set{String}(),\n",
    "                Dict{String, Int64}(),\n",
    "                Dict{String, Int64}(),\n",
    "                Dict{Int64, String}(),\n",
    "                Dict{Int64, String}(),\n",
    "                Vector{Int64}(),\n",
    "                Matrix{Int64}(),\n",
    "                Matrix{Int64}(),\n",
    "                Vector{Int64}(),\n",
    "                Vector{Int64}(),\n",
    "                Matrix{Int64}(),\n",
    "                Matrix{Int64}(),\n",
    "                Vector{Int64}(),\n",
    "                false)\n",
    "    \n",
    "   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hmm(Set{String}(),Set{String}(),Dict{String,Int64}(),Dict{String,Int64}(),Dict{Int64,String}(),Dict{Int64,String}(),Int64[],,,Int64[],Float64[],,,Float64[],false)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = Hmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = Hmm()\n",
    "\n",
    "hmm.possible_words      = possible_words\n",
    "hmm.possible_states     = possible_states\n",
    "hmm.word_to_pos         = word_to_pos\n",
    "hmm.state_to_pos        = state_to_pos\n",
    "hmm.pos_to_word         = map(reverse, word_to_pos)\n",
    "hmm.pos_to_state        = map(reverse, state_to_pos)\n",
    "hmm.initial_counts      = initial_counts\n",
    "hmm.transition_counts   = transition_counts\n",
    "hmm.final_counts        = final_counts\n",
    "hmm.initial_probs       = initial_probs\n",
    "hmm.transition_probs    = transition_probs\n",
    "hmm.emission_probs      = emission_probs\n",
    "hmm.final_probs         = final_probs[:]\n",
    "hmm.trained             = true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom method for showing the HMM: TODO\n",
    "\n",
    "Looking at the past printed info is not very nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Base.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Base.show(io::IO, hmm::Hmm) = print(io, \"\\n possible_tags=$hmm.possible_tags\\n possible_words=$(hmm.possible_words)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set(String[\"sunny\",\"rainy\"])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.possible_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm(Set(String[\"tennis\",\"walk\",\"clean\",\"shop\"]),Set(String[\"sunny\",\"rainy\"]),Dict(\"tennis\"=>4,\"walk\"=>1,\"clean\"=>2,\"shop\"=>3),Dict(\"sunny\"=>2,\"rainy\"=>1),Dict(4=>\"tennis\",2=>\"clean\",3=>\"shop\",1=>\"walk\"),Dict(2=>\"sunny\",1=>\"rainy\"),[2,1],[2 2; 0 5],,[0,3],[0.666667,0.333333],[0.5 0.5; 0.0 0.625],[0.75 0.0 0.25 0.0; 0.25 0.375 0.375 0.0],[0.0,0.375],true)\n"
     ]
    }
   ],
   "source": [
    "println(hmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computations in log domain: why?\n",
    "\n",
    "We will compute logprobabilities since multiplying several probabilities will lead to numerical underflow but summing logprobabilities will not.\n",
    "\n",
    "Notice that sometimes computations in log domain can be tricky. Let us consider the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "Inf\n"
     ]
    }
   ],
   "source": [
    "#srand(12345)\n",
    "#a = rand(10)\n",
    "a = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10]\n",
    "\n",
    "print(log(sum(exp.(a))),\"\\n\")\n",
    "print(log(sum(exp.(10*a))),\"\\n\")\n",
    "print(log(sum(exp.(100*a))),\"\\n\")\n",
    "print(log(sum(exp.(1000*a))),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: sumexp not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: sumexp not defined",
      ""
     ]
    }
   ],
   "source": [
    "sumexp(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously ```log(sum(exp(1000*a)))``` should not be ```Inf``` in order to avoid this numerical inestability we will code our oun ```logsum```function.\n",
    "\n",
    "Nice video explayining the ```logsumexp``` trick\n",
    "\n",
    "- https://www.youtube.com/watch?v=-RVM21Voo7Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition logsum_pair(Any, Any) in module Main at In[76]:1 overwritten at In[142]:1.\n",
      "WARNING: Method definition logsum(Array) in module Main at In[76]:29 overwritten at In[142]:29.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "logsum (generic function with 1 method)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logsum_pair(logx, logy):\n",
    "    \"\"\"\n",
    "    Return log(x+y), avoiding arithmetic underflow/overflow.\n",
    "    logx: log(x)\n",
    "    logy: log(y)\n",
    "\n",
    "    Rationale:\n",
    "        x + y    = e^logx + e^logy = e^logx (1 + e^(logy-logx))\n",
    "    therefore:\n",
    "        log(x+y) = logx + log(1 + e^(logy-logx)) (1)\n",
    "\n",
    "    Likewise,\n",
    "    log(x+y) = logy + log(1 + e^(logx-logy)) (2)\n",
    "\n",
    "    The computation of the exponential overflows earlier and is less precise\n",
    "    for big values than for small values. Due to the presence of logy-logx\n",
    "    (resp. logx-logy), (1) is preferred when logx > logy and (2) is preferred\n",
    "    otherwise.\n",
    "    \"\"\"\n",
    "    if logx == -Inf\n",
    "        return logy\n",
    "    elseif logx > logy\n",
    "        return logx + log1p(exp(logy-logx))\n",
    "    else\n",
    "        return logy + log1p(exp(logx-logy))\n",
    "    end\n",
    "end\n",
    "\n",
    "function logsum(logv::Array):\n",
    "    \"\"\"\n",
    "    Return log(v[0] + v[1] + ...), avoiding arithmetic underflow/overflow.\n",
    "    \"\"\"\n",
    "    res = -Inf\n",
    "    for val in logv\n",
    "        res = logsum_pair(res, val)\n",
    "    end\n",
    "    return res\n",
    "end\n",
    "\n",
    "#function logsum(logv::Float64):\n",
    "#    \"\"\"\n",
    "#    Return log(v[0] + v[1] + ...), avoiding arithmetic underflow/overflow.\n",
    "#    \"\"\"\n",
    "#    res = -Inf\n",
    "#    res = logsum_pair(res, logv)\n",
    "#    return res\n",
    "#end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions from above we don´t have the ```Inf``` problem anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "900.0\n"
     ]
    }
   ],
   "source": [
    "print(logsum(a),\"\\n\")\n",
    "print(logsum(10*a),\"\\n\")\n",
    "print(logsum(100*a),\"\\n\")\n",
    "print(logsum(1000*a),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000003 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7999098843442183"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time logsum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  16 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     3.273 μs (0.00% GC)\n",
       "  median time:      3.276 μs (0.00% GC)\n",
       "  mean time:        3.409 μs (0.00% GC)\n",
       "  maximum time:     16.405 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     8"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = [x for x in 1:50]/10;\n",
    "@benchmark logsum(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficient logsum_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition logsumexp2(Any) in module Main at In[80]:2 overwritten at In[146]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "logsumexp2 (generic function with 1 method)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logsumexp2(X)\n",
    "    alpha = -Inf\n",
    "    r = 0.0\n",
    "    @inbounds for x in X\n",
    "        if x <= alpha\n",
    "            r += exp(x - alpha)\n",
    "        else\n",
    "            r *= exp(alpha - x)\n",
    "            r += 1.0\n",
    "            alpha = x\n",
    "        end\n",
    "    end\n",
    "    return log(r) + alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "900.0\n"
     ]
    }
   ],
   "source": [
    "print(logsumexp2(a),\"\\n\")\n",
    "print(logsumexp2(10*a),\"\\n\")\n",
    "print(logsumexp2(100*a),\"\\n\")\n",
    "print(logsumexp2(1000*a),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000003 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7999098843442183"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time logsumexp2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition logsumexp_batch(Any) in module Main at In[83]:2 overwritten at In[149]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "logsumexp_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logsumexp_batch(X)\n",
    "    alpha = maximum(X)  # Find maximum value in X\n",
    "    log(sum(exp(X-alpha))) + alpha\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  16 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     525.215 ns (0.00% GC)\n",
       "  median time:      529.325 ns (0.00% GC)\n",
       "  mean time:        578.829 ns (0.25% GC)\n",
       "  maximum time:     15.338 μs (95.39% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     191"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = [x for x in 1:50]/10.;\n",
    "@benchmark logsumexp2(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.16 KiB\n",
       "  allocs estimate:  8\n",
       "  --------------\n",
       "  minimum time:     1.108 μs (0.00% GC)\n",
       "  median time:      1.275 μs (0.00% GC)\n",
       "  mean time:        1.494 μs (9.67% GC)\n",
       "  maximum time:     382.514 μs (95.50% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     10"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark logsumexp_batch(aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.331327 seconds (895 allocations: 152.631 MB, 64.28% gc time)\n",
      "  0.073903 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2613.184781452367"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10_000_000\n",
    "X = 500.0*randn(n)\n",
    "\n",
    "@time logsumexp_batch(X)\n",
    "@time logsumexp2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000004 seconds (9 allocations: 528 bytes)\n",
      "  0.000003 seconds (5 allocations: 176 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1176.1838983575794"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "X = 500.0*randn(n)\n",
    "\n",
    "@time logsumexp_batch(X)\n",
    "@time logsumexp2(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing scores for a given sequence\n",
    "\n",
    "\n",
    "For convenience, we will be working with \n",
    "\n",
    "log-probabilities, rather than probabilities. Therefore, if we associate to each circle and arrow in the trellis a score that corresponds\n",
    "to the log-probabilities above, and if we define the score of a path\n",
    "connecting the ${\\tt start}$ and  ${\\tt stop}$ symbols as\n",
    "the sum of the scores of the circles and arrows it traverses, \n",
    "then the goal of **finding the most likely sequence of states (Viterbi decoding) corresponds to finding the path with the highest score**.\n",
    "\n",
    "\n",
    "\n",
    "The trellis scores are given by the following expressions:\n",
    "\n",
    "- For each state $c_k$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{score}_{\\mathrm{init}}(c_k) &=&\n",
    "\\log P_{\\mathrm{init}}(Y_{1} = c_k | \\text{start}).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "- For each position $i \\in {1,\\ldots,N-1}$ and each pair of states $c_k$ and $c_l$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{score}_{\\mathrm{trans}}(i, c_k, c_l) &=&\n",
    "\\log P_{\\mathrm{trans}}(Y_{i+1} = c_k | Y_i = c_l).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "- For each state $c_l$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{score}_{\\mathrm{final}}(c_l) &=&\n",
    "\\log P_{\\mathrm{final}}(\\text{stop} | Y_N = c_l).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "- For each position $i \\in {1,\\ldots,N}$ and state $c_k$:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{score}_{\\mathrm{emiss}}(i, c_k) &=&\n",
    "\\log P_{\\mathrm{emiss}}(X_i = x_i | Y_i = c_k).\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_scores (generic function with 1 method)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_scores(hmm, sequence)\n",
    "    length_sequence = length(sequence.words)\n",
    "    n_states = length(hmm.possible_states)\n",
    "    \n",
    "    initial_scores = log.(hmm.initial_probs)\n",
    "    transition_scores = log.(hmm.transition_probs)\n",
    "\n",
    "    sequence_words_integers = [hmm.word_to_pos[x] for x in sequence.words]\n",
    "    emission_scores = log.(hmm.emission_probs[:, sequence_words_integers])\n",
    "    final_scores = log.(hmm.final_probs)\n",
    "    \n",
    "    return initial_scores, transition_scores, final_scores, emission_scores\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 1\n",
       " 1\n",
       " 3\n",
       " 2"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = train_sequences[1]\n",
    "sequence_words_integers = [hmm.word_to_pos[x] for x in sequence.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 0.75  0.0    0.25   0.0\n",
       " 0.25  0.375  0.375  0.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " 0.75  0.75  0.25   0.0  \n",
       " 0.25  0.25  0.375  0.375"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.emission_probs[:, sequence_words_integers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-0.405465,-1.09861],\n",
       "[-0.693147 -0.693147; -Inf -0.470004],\n",
       "\n",
       "[-Inf,-0.980829],\n",
       "[-0.287682 -0.287682 -1.38629 -Inf; -1.38629 -1.38629 -0.980829 -0.980829])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#log_likelihood, forward = hmm.decoder.run_forward(initial_scores, transition_scores,final_scores, emission_scores)\n",
    "scores = compute_scores(hmm, train_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_scores, transition_scores, final_scores, emission_scores = scores;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -0.405465\n",
       " -1.09861 "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_scores[[hmm.state_to_pos[\"rainy\"],hmm.state_to_pos[\"sunny\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       "   -0.693147  -0.693147\n",
       " -Inf         -0.470004"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -Inf       \n",
       "   -0.980829"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " -0.287682  -0.287682  -1.38629   -Inf       \n",
       " -1.38629   -1.38629   -0.980829    -0.980829"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states: 2\n",
      "length sequence: 4"
     ]
    }
   ],
   "source": [
    "n_states = length(initial_scores)\n",
    "length_sequence = size(emission_scores)[2]\n",
    "print(\"n_states: \", n_states, \"\\n\")\n",
    "print(\"length sequence: \", length_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior decoding\n",
    "\n",
    "\n",
    "Posterior decoding consists\n",
    "in picking state with the highest posterior for each position in the sequence independently; for \n",
    "each $i = 1,\\ldots,N$:\n",
    "\n",
    "\\begin{equation}\n",
    "y_i^* = \\text{argmax}_{y_i \\in \\Lambda} P(Y_i=y_i | X = x).\n",
    "\\end{equation}\n",
    "\n",
    "The **sequence posterior distribution** is the probability of a particular\n",
    "hidden state sequence given that we have observed a particular\n",
    "sequence. Moreover, we will be interested in two other posteriors distributions:\n",
    "the **state posterior distribution**, corresponding to the\n",
    "probability of being in a given state in a certain position given the\n",
    "observed sequence; and the \\textbf{transition posterior distribution},\n",
    "which is the probability of making a particular transition, from position $i$ to\n",
    "$i+1$, given the observed sequence. \n",
    "\n",
    "They are formally defined as follows:\n",
    "\n",
    "- Sequence  Posterior\n",
    "$$P(Y=y|X=x) = \\frac{P(X=x,Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "- State Posterior\n",
    "$$\n",
    "P(Y_i=y_i | X=x)\n",
    "$$\n",
    "\n",
    "- Transition Posterior\n",
    "$$\n",
    "P(Y_{i+1}=y_{i+1},Y_i=y_i| X=x)\n",
    "$$\n",
    "\n",
    "\n",
    "### Computing posteriors involves beeing able to compute $P(X=x)$\n",
    "To compute the posteriors, a first step is to be able to compute the \n",
    "likelihood of\n",
    "the sequence $P(X=x)$, which corresponds to summing the probability of all\n",
    "possible hidden state sequences.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Likelihood\\!:}\\;\\;\\;\\; P(X=x) = \\displaystyle \\sum_{y \\in \\Lambda^N} P(X=x,Y=y).\n",
    "\\end{equation}\n",
    "\n",
    "The number of possible hidden state sequences is exponential in the\n",
    "length of the sequence ($|\\Lambda|^N$),\n",
    " which makes the sum over all of them hard. \n",
    " In our simple\n",
    " example, there are $2^4 = 16$ paths, which we can actually explicitly enumerate\n",
    " and calculate their probability using Equation of the joint probability $P(x,y)$. But this is as far as it goes: for example, for Part-of-Speech\n",
    " tagging with a small tagset of 12 tags and a medium size\n",
    " sentence of length 10, there are $12^{10} = 61 917 364 224$ such\n",
    " paths. \n",
    " \n",
    " Yet, we must be able to compute this sum (sum over $y \\in \\Lambda^N$) to compute the above likelihood\n",
    "formula; this is called the inference problem. For sequence models, there is a well known dynamic programming algorithm,\n",
    "the **Forward-Backward** (FB) algorithm, which allows the computation\n",
    "to be performed in linear time, The runtime is linear with respect\n",
    "to the sequence length. More precisely, \n",
    "the runtime is $O(N|\\Lambda|^2)$. \n",
    "A naive enumeration would cost $O(|\\Lambda|^N)$.\n",
    "\n",
    "The FB algorithm relies on the independence of previous states\n",
    "assumption, which  \n",
    "is illustrated in the trellis view by having arrows only between consecutive states. \n",
    "The FB algorithm defines two auxiliary probabilities, the forward probability and the backward probability. \n",
    "\n",
    "\n",
    "## Efficient forward probability computation\n",
    "\n",
    "The forward probability represents the probability that in position\n",
    "$i$ we are in state $Y_i = c_k$ and that we have observed $x_1,\\ldots,x_i$\n",
    "up to that position. Therefore, its mathematical expression is:\n",
    "\\begin{equation}\n",
    "\\mathbf{Forward \\ Probability\\!:}\\;\\;\\;\\;  \\mathrm{forward}(i, c_k) = P(Y_i = c_k, X_1=x_1,\\ldots, X_i = x_i)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Using the independence assumptions of the HMM we can compute $\\mathrm{forward}(i, c_k)$ using all the forward computations \\{$\\mathrm{forward}(i -1, c)$ for $c \\in \\Lambda$\\}. In order to facilitate the notation of the following argument we will denote by $x_{i:j}$  the assignemnt $X_i = x_i, \\dots, X_j = x_j$. Therefore we can write   $\\mathrm{forward}(i, y_i) $ as $P( y_i, x_{1:i } ) $ and rewrite the forward expression as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "  P( y_i, x_{1:i } ) =  \\sum_{y_{i-1} \\in \\Lambda} P( y_i ,y_{i-1}, x_{1:i } )  =  \\sum_{y_{i-1} \\in \\Lambda} P( x_i  | y_i,  y_{i-1},  x_{1:i-1 } ) \\cdot P(y_i  | y_{i-1},  x_{1:i-1 }) \\cdot P(y_{i-1},  x_{1:i-1 })  \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Using the **Observation independence** and the **Independence of previous states** properties of the first order HMM we have $P( x_i  | y_i,  y_{i-1},  x_{1:i-1 } ) = P( x_i  | y_i) $ and $P(y_i  | y_{i-1},  x_{1:i-1 })  = P(y_i  | y_{i-1})  $. Therefore the previous equation can be written, \n",
    "for $i \\in \\{2,\\dots,N\\}$ (where $N$ is the length of the sequence), as \n",
    "\n",
    "\\begin{equation}\n",
    " \\mathrm{forward}(i, y_i)  = \\sum_{y_{i-1} \\in \\Lambda} P( x_i  | y_i, ) \\cdot P(y_i  | y_{i-1}) \\cdot \\mathrm{forward}(i-1, y_{i-1})   \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The previous equation proves that  the forward probability can be defined by the\n",
    "following recurrence rule: \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{forward}(1, c_k)&=& P_{\\text{init}}(c_k|\\text{start}) \\times P_{\\mathrm{emiss}}(x_1 | c_k)\n",
    " \\\\\n",
    " \\mathrm{forward}(i, c_k) &=& \\left(  \\sum_{c_l \\in \\Lambda} P_{\\mathrm{trans}}(c_k | c_l) \\times \\mathrm{forward}(i-1, c_l) \\right) \\times P_{\\mathrm{emiss}}(x_i | c_k) \n",
    " \\\\\n",
    "  \\mathrm{forward}(N+1, \\text{stop}) &=& \\sum_{c_l \\in \\Lambda} P_{\\text{final}}(\\text{ stop} | c_l) \\times \\mathrm{forward}(N, c_l).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Using the forward trellis one can compute the likelihood simply as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(X=x) = \\mathrm{forward}(N+1, \\text{ stop}).\n",
    "\\end{equation}\n",
    "\n",
    "Although the forward probability is enough to calculate the likelihood of a given sequence, we will also need the backward probability to calculate the state posteriors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 2 entries:\n",
       "  \"sunny\" => 2\n",
       "  \"rainy\" => 1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.state_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Int64} with 4 entries:\n",
       "  \"tennis\" => 4\n",
       "  \"walk\"   => 1\n",
       "  \"clean\"  => 2\n",
       "  \"shop\"   => 3"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.word_to_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition run_log_forward(Any, Any, Any, Any) in module Main at In[101]:5 overwritten at In[155]:5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "run_log_forward (generic function with 1 method)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_log_forward(initial_scores,\n",
    "                         transition_scores,\n",
    "                         final_scores,\n",
    "                         emission_scores)\n",
    "    \"\"\"\n",
    "    Compute the log_forward computations\n",
    "    \n",
    "    Assume there are K possible states and a sequence of length N.\n",
    "    This method will compute iteritavely the log_forward quantities.\n",
    "    \n",
    "    * log_f is a K x N Array.\n",
    "    * log_f[:,i] will contain the forward quantities at position i.\n",
    "    * log_f[:,i] is a vector of size K\n",
    "    \n",
    "    Returns\n",
    "    - log_f: Array of size K x N\n",
    "    \"\"\"\n",
    "    length_sequence = size(emission_scores)[2]  \n",
    "    n_states = length(hmm.state_to_pos)         # number of states\n",
    "    \n",
    "    # Forward variables initialized to Infinity because log(0) = Inf\n",
    "    log_f = zeros(n_states, length_sequence) .+ Inf\n",
    "\n",
    "    # Initialization\n",
    "    log_f[:,1] = emission_scores[:,1] + initial_scores\n",
    "    \n",
    "    for n in 2:length_sequence\n",
    "        for s in 1:n_states\n",
    "            log_f[s,n] = logsum(log_f[:,n-1] + transition_scores[:,s]) + emission_scores[s,n]\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    log_likelihood = logsum(log_f[:,length_sequence] + final_scores)    \n",
    "    return log_likelihood, log_f\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood: -5.068232326005127\n",
      "log_forward computations:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×4 Array{Float64,2}:\n",
       " -0.693147  -1.67398  -3.75342  -Inf     \n",
       " -2.48491   -2.58335  -2.94018    -4.0874"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood, log_forward = run_log_forward(initial_scores,\n",
    "                                              transition_scores,\n",
    "                                              final_scores,\n",
    "                                              emission_scores)\n",
    "\n",
    "print(\"log_likelihood: \", log_likelihood)\n",
    "print(\"\\nlog_forward computations:\"); log_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Efficient backward probability computation\n",
    "\n",
    "\n",
    "\n",
    "The backward probability is similar to the forward probability, but operates in the inverse direction.\n",
    "It represents the probability of observing $x_{i+1},\\ldots,x_N$ from position $i+1$ up to $N$, given that at position $i$ we are at state $Y_i = c_l$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Backward \\ Probability\\!:}\\;\\;\\;\\;  \\text{backward}(i, c_l) = P(X_{i+1}=x_{i+1},\\ldots, X_N=x_N | Y_i = c_l).\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Using the independence assumptions of the HMM we can compute $\\text{backward}(i, c_k)$ using all the backward computations $\\text{backward}(i +1, c)$ for $c \\in \\Lambda$.\n",
    "\n",
    "Therefore we can write   $\\text{backward}(i, y_i) $ as $P( x_{i+1:N} | y_i ) $ and rewrite the forward expression as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "  P( x_{i+1:N} | y_i ) =  \\sum_{y_{i+1} \\in \\Lambda} P( x_{i+1:N}, y_{i+1} | y_i)  =  \\sum_{y_{i+1} \\in \\Lambda} P( x_{i+2:N} | y_i, y_{i+1}, x_{i+1}) \n",
    "   P( x_{i+1}, |  y_{i+1},  y_{i}) P( y_{i+1} | y_i)\n",
    "\\end{equation}\n",
    "\n",
    "Using the previous equation we have proved that the backward probability can be defined by the following recurrence rule:\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{backward}(N, c_l) &=& P_{\\text{final}}(\\text{stop} | c_l)  \\\\\n",
    "\\text{backward}(i, c_l) &=&  \\displaystyle \\sum_{c_k \\in \\Lambda} P_{\\text{trans}}(c_k | c_l) \\times \n",
    "\\text{backward}(i+1, c_k) \\times P_{\\text{emiss}}(x_{i+1} | c_k) \n",
    " \\\\\n",
    "  \\mathrm{backward}(0, \\text{start}) &=& \\sum_{c_k \\in \\Lambda} P_{\\mathrm{init}}(c_k | \\text{ start}) \\times \\mathrm{backward}(1, c_k) \\times P_{\\mathrm{emiss}}(x_{1} | c_k).\n",
    " \\end{eqnarray}\n",
    "\n",
    "Using the backward trellis one can compute the likelihood simply as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(X=x) = \\mathrm{backward}(0, \\text{start}).\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition run_log_backward(Any, Any, Any, Any) in module Main at In[103]:5 overwritten at In[157]:5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "run_log_backward (generic function with 1 method)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_log_backward(initial_scores,\n",
    "                          transition_scores,\n",
    "                          final_scores,\n",
    "                          emission_scores)\n",
    "    \"\"\"\n",
    "    Compute the log_backward computations\n",
    "    \n",
    "    Assume there are K possible states and a sequence of length N.\n",
    "    This method will compute iteritavely the log_forward quantities.\n",
    "    \n",
    "    * log_b is a K x N Array.\n",
    "    * log_b[:,i] will contain the forward quantities at position i.\n",
    "    * log_b[:,i] is a vector of size K\n",
    "    \n",
    "    Returns\n",
    "    - log_b::Array{Float64,2}, size(log_b)=(K,N)\n",
    "    - log_likelihood::Float64\n",
    "    \"\"\"\n",
    "    length_sequence = size(emission_scores)[2]\n",
    "    n_states = length(initial_scores)\n",
    "    log_b = zeros(n_states, length_sequence) - Inf\n",
    "\n",
    "    # Initialization\n",
    "    log_b[:,length_sequence] = final_scores\n",
    "\n",
    "    for n in length_sequence-1:-1:1\n",
    "        for s in 1:n_states\n",
    "             log_b[s,n] = logsum(log_b[:,n+1] + transition_scores[s,:] + emission_scores[:,n+1])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    log_likelihood = logsum(log_b[:,1] + initial_scores + emission_scores[:,1])\n",
    "    \n",
    "    return log_likelihood, log_b\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "log_likelihood: -5.068232326005126\n",
      "log_backward computations:"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float64,2}:\n",
       "   -4.41864  -5.73879 \n",
       "   -3.67819  -3.8825  \n",
       "   -2.65481  -2.43166 \n",
       " -Inf        -0.980829"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood, log_backward = run_log_backward(initial_scores,\n",
    "                                                transition_scores,\n",
    "                                                final_scores,\n",
    "                                                emission_scores)\n",
    "\n",
    "print(\"\\nlog_likelihood: \", log_likelihood)\n",
    "print(\"\\nlog_backward computations:\"); log_backward'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The forward backward algorithm\n",
    "\n",
    "Now we will see why we migh want to compute the forward and backward quantities.\n",
    "\n",
    "We have seen how we can compute the probability of a sequence $x$ using the the forward and backward probabilities by computing  $\\mathrm{forward}(N+1, \\text{ stop})$ and $ \\mathrm{backward}(0, \\text{ start})$ respectively. Moreover,  the probability of a sequence $x$ can be computed with both forward and backward probabilities at a particular position $i$. \n",
    "\n",
    "The probability of a  given sequence $x$ at any position $i$ in the sequence can be computed\n",
    "as follows:\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "  P(X=x) &=& \n",
    "  \\sum_{c_k \\in \\Lambda} P(X_1=x_1,\\ldots, X_N=x_N,Y_i=c_k)\\nonumber\\\\\n",
    "  & =&\n",
    "  \\sum_{c_k \\in \\Lambda} \n",
    "  \\underbrace{P(X_1=x_1,\\ldots, X_i=x_i, Y_i=c_k)}_{\\mathrm{forward}(i,c_k)} \\times \n",
    "  \\underbrace{P(X_{i+1}=x_{i+1},\\ldots, X_N=x_N| Y_i=c_k)}_{\\mathrm{backward}(i,c_k)}\\nonumber\\\\\n",
    "  &=& \\sum_{c_k \\in \\Lambda} \\mathrm{forward}(i,c_k) \\times \\mathrm{backward}(i,c_k).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "\n",
    "This equation will work for any choice of $i$. Although redundant, this fact is useful when implementing an\n",
    "HMM as a sanity check that the computations are being performed\n",
    "correctly, since one can compute this expression for several $i$; they should all yield the same value. \n",
    "\n",
    "The following pseudocode shows the the forward backward algorithm. \n",
    "\n",
    "The reader can notice that the $forward$ and $backward$ computations in the algorithm make use of $P_{emiss}$ and $P_{trans}$. There are a couple of details that should be taken into account if the reader wants to understand the algorithm using scores instead of probabilities.\n",
    "\n",
    "\n",
    "- $forward(i,x,\\hat{c})$  is computed using $P_{emiss}(x_i | \\hat{c})$ which does not depend on the sum over all possible states $c_k \\in  \\Lambda $. Therefore when taking the logarithm of the sum over all possible states the recurrence of the forward computations can be split as a sum of two logarithms.\n",
    "\n",
    "\n",
    "- $backward(i,x,\\hat{c})$  is computed using $ P_{\\text{trans}}(c_k | \\hat{c} )$ and $P_{\\text{emiss}}(x_{i+1} | c_k) $ both of  which  depend on $c_k$. Therefore when taking the logarithm of the sum the expression cannot be split as a sum of logarithms.\n",
    "\n",
    "\n",
    "\n",
    "Given the forward and backward probabilities, one can compute both the state\n",
    "and transition posteriors as follows:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{State \\ Posterior\\!:}\\;\\;\\;\\;  & P(Y_i = y_i| X=x) = \\frac{\\mathrm{forward}(i,x, y_i) \\times \n",
    " \\mathrm{backward}(i,x, y_i)}{P(X=x)}\\\\\n",
    " \\mathbf{Transition \\ Posterior\\!:}\\;\\;\\;\\; &\n",
    " P(Y_i = y_i, Y_{i+1} = y_{i+1} | X=x)= \\nonumber\\\\\n",
    " &\n",
    "   \\frac{\\mathrm{forward}(i, y_i) \\times \n",
    "   P_{\\mathrm{trans}}(y_{i+1}|y_i) \\times\n",
    "   P_{\\mathrm{emiss}}(x_{i+1}|y_{i+1}) \\times\n",
    " \\mathrm{backward}(i+1, y_{i+1})}{P(X=x)}\n",
    "\\end{align}\n",
    "\n",
    "As a practical example, given that the person performs the sequence of actions $\\text{ walk} \\text{ walk} \\text{ shop} \\text{ clean}$, we want to know the probability of having been raining in the second day. The state posterior probability for this event can be seen as the probability that the sequence of actions above was generated by a sequence of weathers and where it was raining in the second day. In this case, the possible sequences would be all the sequences which have {\\tt rainy} in the second position.\n",
    "\n",
    "\n",
    "Using the state posteriors, we are ready to perform posterior\n",
    "decoding. \n",
    "The strategy is to compute the state posteriors \n",
    "for each position $i \\in \\{1,\\ldots,N\\}$\n",
    "and each state $c_k \\in \\Lambda$, and \n",
    "then pick the arg-max at each position:\n",
    "\n",
    "$$\n",
    "{\\widehat y_i} := \\text{argmax}_{y_i \\in \\Lambda} P(Y_i=y_i| X=x).\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "    def compute_posteriors(self, initial_scores, transition_scores,\n",
    "                           final_scores, emission_scores):\n",
    "        \"\"\"\n",
    "        Compute the state and transition posteriors:\n",
    "        - The state posteriors are the probability of each state\n",
    "        occurring at each position given the sequence of observations.\n",
    "        - The transition posteriors are the joint probability of two states\n",
    "        in consecutive positions given the sequence of observations.\n",
    "        Both quantities are computed via the forward-backward algorithm.\n",
    "        \"\"\"\n",
    "\n",
    "        length = np.size(emission_scores, 0)  # Length of the sequence.\n",
    "        num_states = np.size(emission_scores, 1)  # Number of states.\n",
    "\n",
    "        log_likelihood, forward = self.decoder.run_forward(initial_scores,\n",
    "                                                           transition_scores,\n",
    "                                                           final_scores,\n",
    "                                                           emission_scores)\n",
    "        log_likelihood, backward = self.decoder.run_backward(initial_scores,\n",
    "                                                             transition_scores,\n",
    "                                                             final_scores,\n",
    "                                                             emission_scores)\n",
    "\n",
    "        state_posteriors = np.zeros([length, num_states])  # State posteriors.\n",
    "        for pos in xrange(length):\n",
    "            state_posteriors[pos, :] = forward[pos, :] + backward[pos, :]\n",
    "            state_posteriors[pos, :] -= log_likelihood\n",
    "\n",
    "        transition_posteriors = np.zeros([length-1, num_states, num_states])\n",
    "        for pos in xrange(length-1):\n",
    "            for prev_state in xrange(num_states):\n",
    "                for state in xrange(num_states):\n",
    "                    transition_posteriors[pos, state, prev_state] = \\\n",
    "                        forward[pos, prev_state] + \\\n",
    "                        transition_scores[pos, state, prev_state] + \\\n",
    "                        emission_scores[pos+1, state] + \\\n",
    "                        backward[pos+1, state]\n",
    "                    transition_posteriors[pos, state, prev_state] -= log_likelihood\n",
    "\n",
    "        state_posteriors = np.exp(state_posteriors)\n",
    "        transition_posteriors = np.exp(transition_posteriors)\n",
    "\n",
    "        return state_posteriors, transition_posteriors, log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(emission_scores)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -1.67398\n",
       " -2.58335"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_forward[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition compute_state_posteriors(Any, Any, Any, Any) in module Main at In[107]:2 overwritten at In[161]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "compute_state_posteriors (generic function with 1 method)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_state_posteriors(initial_scores, transition_scores, final_scores, emission_scores)\n",
    "    num_states = size(emission_scores)[1]  # Number of states.\n",
    "    length = size(emission_scores)[2]      # Length of the sequence.\n",
    "    \n",
    "    log_likelihood, forward =  run_log_forward(initial_scores,\n",
    "                                          transition_scores,\n",
    "                                          final_scores,\n",
    "                                          emission_scores)\n",
    "    \n",
    "    log_likelihood, backward = run_log_backward(initial_scores,\n",
    "                                            transition_scores,\n",
    "                                            final_scores,\n",
    "                                            emission_scores)\n",
    "    \n",
    "    state_posteriors = zeros(num_states, length)      \n",
    "    for pos in 1:length\n",
    "        state_posteriors[:, pos] = forward[:, pos] + backward[:, pos] - log_likelihood\n",
    "    end\n",
    "    return state_posteriors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition posterior_decoding(Any) in module Main at In[108]:2 overwritten at In[162]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "posterior_decoding (generic function with 1 method)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function posterior_decoding(state_posteriors)\n",
    "    return mapslices(indmax, state_posteriors, 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×4 Array{Int64,2}:\n",
       " 1  1  2  2"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_posteriors = compute_state_posteriors(initial_scores, transition_scores, final_scores, emission_scores)\n",
    "posterior_decoding(state_posteriors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "\n",
    "\n",
    "TODO: 1 feb: \n",
    "- Make a reader for this function. \n",
    "- Train HMM with the conll data.\n",
    "- Do posterior decoding.\n",
    "\n",
    "First sentence in  \"train-02-21.conll\"\n",
    "\n",
    "    1\tNo\t_\tRB\tRB\t_\t4\tVMOD\t_\t_\n",
    "    2\t,\t_\t.\t,\t_\t4\tP\t_\t_\n",
    "    3\tit\t_\tPR\tPRP\t_\t4\tSUB\t_\t_\n",
    "    4\twas\t_\tVB\tVBD\t_\t0\tROOT\t_\t_\n",
    "    5\tn't\t_\tRB\tRB\t_\t4\tVMOD\t_\t_\n",
    "    6\tBlack\t_\tNN\tNNP\t_\t7\tNMOD\t_\t_\n",
    "    7\tMonday\t_\tNN\tNNP\t_\t4\tPRD\t_\t_\n",
    "    8\t.\t_\t.\t.\t_\t4\tP\t_\t_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition build_sequences_from_data(Any) in module Main at In[110]:2 overwritten at In[164]:2.\n",
      "WARNING: Method definition #build_sequences_from_data(Array{Any, 1}, Main.#build_sequences_from_data, Any) in module Main overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "build_sequences_from_data (generic function with 1 method)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function build_sequences_from_data(file_path; min_sequence_length_allowed=5)\n",
    "    f = open(file_path, \"r\")\n",
    "    lines = readlines(f)\n",
    "    sequences = Array{Sequence}([])\n",
    "    sequence_counter = 0\n",
    "    min_seq_length = min_sequence_length_allowed\n",
    "    max_seq_length = 0\n",
    "    words = Array{String}([])\n",
    "    tags = Array{String}([])\n",
    "\n",
    "    for line in lines\n",
    "        line_splitted = split(line, \"\\t\")\n",
    "\n",
    "        if line_splitted[1] == \"\\n\"\n",
    "            current_lenght = length(words)\n",
    "            \n",
    "            if (current_lenght < min_sequence_length_allowed) continue end\n",
    "            if (current_lenght < min_seq_length) min_seq_length = current_lenght end\n",
    "            if (current_lenght > max_seq_length) max_seq_length = current_lenght end\n",
    "            \n",
    "            push!(sequences, Sequence(words,tags))\n",
    "            words = Array{String}([])\n",
    "            tags = Array{String}([])\n",
    "            sequence_counter +=1\n",
    "        else\n",
    "            push!(words, line_splitted[2])\n",
    "            push!(tags, line_splitted[5])    \n",
    "        end\n",
    "    end\n",
    "    print(\"\\nNumber sequences: \", sequence_counter)\n",
    "    print(\"\\nMin sequence length: \", min_seq_length)\n",
    "    print(\"\\nMax sequence length: \", max_seq_length)\n",
    "    return sequences\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number sequences: 39642\n",
      "Min sequence length: 3\n",
      "Max sequence length: 141\n",
      "Number sequences: 1684\n",
      "Min sequence length: 3\n",
      "Max sequence length: 118\n",
      "Number sequences: 2408\n",
      "Min sequence length: 3\n",
      "Max sequence length: 67"
     ]
    }
   ],
   "source": [
    "file_path_train = homedir() * \"/Documents/Datasets/conll/train-02-21.conll\"\n",
    "file_path_valid = homedir() * \"/Documents/Datasets/conll/dev-22.conll\"\n",
    "file_path_test = homedir() * \"/Documents/Datasets/conll/test-23.conll\"\n",
    "\n",
    "train_seq = build_sequences_from_data(file_path_train, min_sequence_length_allowed=3);\n",
    "valid_seq = build_sequences_from_data(file_path_valid, min_sequence_length_allowed=3);\n",
    "test_seq = build_sequences_from_data(file_path_test, min_sequence_length_allowed=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train HMM and do posterior decoding with the conll data\n",
    "\n",
    "    hmm = hmmc.HMM(corpus.word_dict, corpus.tag_dict)\n",
    "    hmm.train_supervised(train_seq)\n",
    "    hmm.print_transition_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition assign_elements_to_integers(Any) in module Main at In[44]:2 overwritten at In[112]:2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "assign_elements_to_integers (generic function with 1 method)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function assign_elements_to_integers(elements)\n",
    "    element_to_pos = Dict{String, Int64}()\n",
    "    for (k,e) in enumerate(elements)\n",
    "        element_to_pos[e] = k\n",
    "    end\n",
    "    return element_to_pos\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_possible_words_tags (generic function with 1 method)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_possible_words_tags(sequences::Array{Sequence})\n",
    "    possible_words = Set{String}([])\n",
    "    possible_states = Set{String}([])\n",
    "    \n",
    "    for sequence in sequences\n",
    "        for (word,tag) in zip(sequence.words, sequence.labels)\n",
    "            push!(possible_words, word)\n",
    "            push!(possible_states, tag)\n",
    "        end\n",
    "    end\n",
    "    return possible_words, possible_states\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Set(String[\"rearrangement\",\"photosynthesis\",\"Kensetsu\",\"whiz\",\"cost-benefit\",\"gathered\",\"Core\",\"underground\",\"Shinpan\",\"8.63\"  …  \"137,200\",\"convincing\",\"NV\",\"non-violent\",\"156.7\",\"2233.9\",\"134,550\",\"money-transfer\",\"shorten\",\"Freedman\"]),Set(String[\"CC\",\".\",\"PDT\",\"VBP\",\"#\",\"VBD\",\"WRB\",\"VBG\",\"NNS\",\"NN\"  …  \"MD\",\"RP\",\"JJ\",\"\\$\",\"JJR\",\"TO\",\"PRP\",\"NNPS\",\"UH\",\"POS\"]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_words, possible_states =  get_possible_words_tags(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_pos = assign_elements_to_integers(possible_words);\n",
    "state_to_pos = assign_elements_to_integers(possible_states);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_final_counts! (generic function with 1 method)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_initial_counts!(initial_counts, seq, state_to_pos)\n",
    "    initial_counts[state_to_pos[seq.labels[1]]] = initial_counts[state_to_pos[seq.labels[1]]] + 1\n",
    "end\n",
    "\n",
    "function update_transition_counts!(transition_counts, seq, state_to_pos)\n",
    "    for (t1,t2) in zip(seq.labels[1:end-1], seq.labels[2:end])\n",
    "        transition_counts[state_to_pos[t1], state_to_pos[t2]] += 1 \n",
    "    end    \n",
    "end\n",
    "\n",
    "function update_emission_counts!(emission_counts, seq, state_to_pos, word_to_pos)\n",
    "    for (t,w) in zip(seq.labels, seq.words)\n",
    "        emission_counts[state_to_pos[t], word_to_pos[w]] += 1 \n",
    "    end \n",
    "end\n",
    "\n",
    "function update_final_counts!(final_counts, seq, state_to_pos)\n",
    "    final_counts[state_to_pos[seq.labels[end]]] +=1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sufficient_statistics_hmm (generic function with 1 method)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sufficient_statistics_hmm(sequences, state_to_pos, word_to_pos)\n",
    "    \n",
    "    n_states = length(state_to_pos)\n",
    "    n_words = length(word_to_pos)\n",
    "    \n",
    "    initial_counts      = zeros(n_states)\n",
    "    transition_counts   = zeros(n_states, n_states)\n",
    "    final_counts        = zeros(n_states) \n",
    "    emission_counts     = zeros(n_states, n_words)\n",
    "    for seq in sequences\n",
    "        update_initial_counts!(initial_counts, seq, state_to_pos)\n",
    "        update_transition_counts!(transition_counts, seq,  state_to_pos)\n",
    "        update_emission_counts!(emission_counts, seq,  state_to_pos, word_to_pos) \n",
    "        update_final_counts!(final_counts, seq,  state_to_pos) \n",
    "    end\n",
    "    \n",
    "    return initial_counts, transition_counts, final_counts, emission_counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit! (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit!(hmm::Hmm, sequences::Array{Sequence})\n",
    "    \n",
    "    possible_words, possible_states =  get_possible_words_tags(sequences)\n",
    "    word_to_pos = assign_elements_to_integers(possible_words);\n",
    "    state_to_pos = assign_elements_to_integers(possible_states);\n",
    "    \n",
    "    hmm.word_to_pos = word_to_pos\n",
    "    hmm.state_to_pos = state_to_pos\n",
    "    hmm.pos_to_word = map(reverse, hmm.state_to_pos)\n",
    "    hmm.pos_to_state = map(reverse, hmm.state_to_pos)\n",
    "\n",
    "    counts = sufficient_statistics_hmm(sequences, state_to_pos, word_to_pos)\n",
    "    initial_counts, transition_counts, final_counts, emission_counts = counts\n",
    "    \n",
    "    hmm.possible_words = possible_words\n",
    "    hmm.possible_states = possible_states\n",
    "    \n",
    "    hmm.initial_counts = initial_counts\n",
    "    hmm.transition_counts = transition_counts\n",
    "    hmm.final_counts = final_counts\n",
    "    hmm.emission_counts = emission_counts\n",
    "    \n",
    "    ### This could be rewritten using for loops and it could be much cleaarer\n",
    "    hmm.initial_probs = (initial_counts / sum(initial_counts))\n",
    "    hmm.transition_probs = transition_counts./(sum(transition_counts, 2) + final_counts)\n",
    "    # vec is added here because hmm.final_probs is defined as a Vector and \n",
    "    # sum(transition_counts, 2) is a  matrix of size (K,1) instead of a vector of size (K,)\n",
    "    hmm.final_probs =  final_counts ./ (vec(sum(transition_counts, 2)) + final_counts )\n",
    "    hmm.emission_probs = (emission_counts ./ sum(emission_counts, 2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hmm(Set{String}(),Set{String}(),Dict{String,Int64}(),Dict{String,Int64}(),Dict{Int64,String}(),Dict{Int64,String}(),Int64[],Array{Int64}(0,0),Array{Int64}(0,0),Int64[],Float64[],Array{Float64}(0,0),Array{Float64}(0,0),Float64[],false)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm = Hmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit!(hmm, train_seq);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior inference with a HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_scores (generic function with 2 methods)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_scores(hmm::Hmm, sequence::Sequence)\n",
    "    \n",
    "    length_sequence = length(sequence.words)\n",
    "    n_states = length(hmm.possible_states)\n",
    "    \n",
    "    initial_scores = log.(hmm.initial_probs)\n",
    "    transition_scores = log.(hmm.transition_probs)\n",
    "    sequence_words_integers = [hmm.word_to_pos[x] for x in sequence.words]\n",
    "    \n",
    "    emission_scores = log.(hmm.emission_probs[:, sequence_words_integers])\n",
    "    final_scores = log.(hmm.final_probs)\n",
    "    \n",
    "    return initial_scores, transition_scores, final_scores, emission_scores\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_state_posteriors (generic function with 1 method)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_state_posteriors(initial_scores, transition_scores, final_scores, emission_scores)\n",
    "    num_states = size(emission_scores)[1]  # Number of states.\n",
    "    length = size(emission_scores)[2]      # Length of the sequence.\n",
    "    \n",
    "    log_likelihood, forward =  run_log_forward(initial_scores,\n",
    "                                          transition_scores,\n",
    "                                          final_scores,\n",
    "                                          emission_scores)\n",
    "    \n",
    "    log_likelihood, backward = run_log_backward(initial_scores,\n",
    "                                            transition_scores,\n",
    "                                            final_scores,\n",
    "                                            emission_scores)\n",
    "    \n",
    "    state_posteriors = zeros(num_states, length)      \n",
    "    for pos in 1:length\n",
    "        state_posteriors[:, pos] = forward[:, pos] + backward[:, pos] - log_likelihood\n",
    "    end\n",
    "    return state_posteriors\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posterior_decode (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function posterior_decode(hmm::Hmm, sequence::Sequence; return_integers=false)  \n",
    "    initial_scores, transition_scores, final_scores, emission_scores = compute_scores(hmm, sequence)\n",
    "    state_posteriors = compute_state_posteriors(initial_scores, transition_scores, final_scores, emission_scores)\n",
    "    predicted_tags = mapslices(indmax, state_posteriors, 1)\n",
    "    \n",
    "    if return_integers == false\n",
    "        return vec([hmm.pos_to_state[tag] for tag in predicted_tags])\n",
    "    else\n",
    "        return predicted_tags\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×49 Array{String,2}:\n",
       " \"IN\"  \"DT\"  \"NNP\"  \"CD\"  \"NN\"  \"IN\"  \"``\"  …  \"VBN\"  \"TO\"  \"NNP\"  \"NNP\"  \".\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_decode(hmm, train_seq[1])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×49 Array{String,2}:\n",
       " \"IN\"  \"DT\"  \"NNP\"  \"CD\"  \"NN\"  \"IN\"  \"``\"  …  \"VBN\"  \"TO\"  \"NNP\"  \"NNP\"  \".\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_decode(hmm, train_seq[1])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_seq[1].labels .== posterior_decode(hmm, train_seq[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(train_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin\n",
    "    total_predicted_states = 0\n",
    "    total_correct = 0\n",
    "    for seq in train_seq\n",
    "        total_correct += sum(seq.labels .== posterior_decode(hmm, seq))\n",
    "        total_predicted_states += length(seq) \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.970337716362044"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", total_correct/total_predicted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TODO\n",
    "\n",
    "- Confusion matrix: check which labels (states) are the most incorretly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi decoding: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
