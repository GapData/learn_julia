{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelize code using native julia methods\n",
    "\n",
    "This notebook presents an example of a typical a parallel problem (count stuff on a big dataset)\n",
    "and uses native julia conde only to solve it. The code will involve two steps:\n",
    "\n",
    "- 1) Split data across processes, make independent computations on each process and get partial results\n",
    "- 2) Join partial results\n",
    "\n",
    "This notebook will focus on the use of the functions pmap, @spawn, fetch and remotecall.\n",
    "\n",
    "Some related material:\n",
    "\n",
    "- http://docs.julialang.org/en/release-0.5/manual/parallel-computing/\n",
    "- https://github.com/JuliaLang/julia/blob/master/examples/wordcount.jl\n",
    "- https://blog.ajdecon.org/parallel-word-count-with-julia-an-interesting/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "big_array = rand(1:10, 10^8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_elements (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function count_elements(array::Array{Int64})\n",
    "    n = length(array)\n",
    "    counts = Dict{Int64}{Int64}()\n",
    "    for i in array\n",
    "        if i in keys(counts)\n",
    "            counts[i] += 1 \n",
    "        else\n",
    "            counts[i] = 1\n",
    "        end\n",
    "    end\n",
    "    return counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.349756 seconds (3.19 k allocations: 137.636 KB)\n"
     ]
    }
   ],
   "source": [
    "@time result_sequential = count_elements(big_array);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faster way to create counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function count_elements2(array::Array{Int64})\n",
    "    n = length(array)\n",
    "    counts = Dict{Int64}{Int64}()\n",
    "    for i in array\n",
    "        counts[i] = get(counts,i,0) + 1\n",
    "    end\n",
    "    return counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@time count_elements2(big_array);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pmap function\n",
    "\n",
    "Now we will build a custom reducer to aggregate the partial results then we will split the data\n",
    "into similar size chunks and split the workload into different processess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_reduce (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducer\n",
    "function count_reduce(array_of_count_dicts)\n",
    "    counts_combined = Dict{Int64}{Int64}()\n",
    "    \n",
    "    for d in array_of_count_dicts\n",
    "        for k in keys(d)\n",
    "            if k in keys(counts_combined)\n",
    "                counts_combined[k] += d[k]  \n",
    "            else\n",
    "                counts_combined[k] = d[k] \n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return counts_combined\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: On worker 2:\nUndefVarError: #count_elements not defined\n in deserialize_datatype at ./serialize.jl:823\n in handle_deserialize at ./serialize.jl:571\n in deserialize_msg at ./multi.jl:120\n in message_handler_loop at ./multi.jl:1317\n in process_tcp_streams at ./multi.jl:1276\n in #618 at ./event.jl:68\n in #remotecall_fetch#606(::Array{Any,1}, ::Function, ::Function, ::Base.Worker, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1070\n in remotecall_fetch(::Function, ::Base.Worker, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1062\n in #remotecall_fetch#609(::Array{Any,1}, ::Function, ::Function, ::Int64, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1080\n in remotecall_fetch(::Function, ::Int64, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1080\n in #remotecall_pool#689(::Array{Any,1}, ::Function, ::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:93\n in remotecall_pool(::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:91\n in #remotecall_fetch#692(::Array{Any,1}, ::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:124\n in remotecall_fetch(::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:124\n in (::Base.###697#698#700{WorkerPool,#count_elements})(::Array{Any,1}, ::Function, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:151\n in (::Base.##697#699)(::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:151\n in macro expansion at ./asyncmap.jl:63 [inlined]\n in (::Base.##755#757{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:360\n\n...and 3 other exceptions.\n\nwhile loading In[7], in expression starting on line 7",
     "output_type": "error",
     "traceback": [
      "LoadError: On worker 2:\nUndefVarError: #count_elements not defined\n in deserialize_datatype at ./serialize.jl:823\n in handle_deserialize at ./serialize.jl:571\n in deserialize_msg at ./multi.jl:120\n in message_handler_loop at ./multi.jl:1317\n in process_tcp_streams at ./multi.jl:1276\n in #618 at ./event.jl:68\n in #remotecall_fetch#606(::Array{Any,1}, ::Function, ::Function, ::Base.Worker, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1070\n in remotecall_fetch(::Function, ::Base.Worker, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1062\n in #remotecall_fetch#609(::Array{Any,1}, ::Function, ::Function, ::Int64, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1080\n in remotecall_fetch(::Function, ::Int64, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./multi.jl:1080\n in #remotecall_pool#689(::Array{Any,1}, ::Function, ::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:93\n in remotecall_pool(::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:91\n in #remotecall_fetch#692(::Array{Any,1}, ::Function, ::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:124\n in remotecall_fetch(::Function, ::WorkerPool, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:124\n in (::Base.###697#698#700{WorkerPool,#count_elements})(::Array{Any,1}, ::Function, ::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:151\n in (::Base.##697#699)(::Array{Int64,1}, ::Vararg{Array{Int64,1},N}) at ./workerpool.jl:151\n in macro expansion at ./asyncmap.jl:63 [inlined]\n in (::Base.##755#757{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:360\n\n...and 3 other exceptions.\n\nwhile loading In[7], in expression starting on line 7",
      "",
      " in sync_end() at ./task.jl:311",
      " in done(::Base.AsyncCollector, ::Base.AsyncCollectorState) at ./asyncmap.jl:124",
      " in pump_source(::Base.AsyncGenerator, ::Base.AsyncGeneratorState) at ./asyncmap.jl:185",
      " in next(::Base.AsyncGenerator, ::Base.AsyncGeneratorState) at ./asyncmap.jl:201",
      " in _collect(::UnitRange{Int64}, ::Base.AsyncGenerator, ::Base.HasEltype, ::Base.SizeUnknown) at ./array.jl:282",
      " in #pmap#714(::Bool, ::Int64, ::Void, ::Int64, ::Float64, ::Function, ::Void, ::Void, ::Void, ::Base.#pmap, ::WorkerPool, ::#count_elements, ::Array{Array{Int64,1},1}) at ./pmap.jl:121",
      " in pmap(::WorkerPool, ::Function, ::Array{Array{Int64,1},1}) at ./pmap.jl:80",
      " in #pmap#726(::Array{Any,1}, ::Function, ::Function, ::Array{Array{Int64,1},1}) at ./pmap.jl:146",
      " in pmap(::Function, ::Array{Array{Int64,1},1}) at ./pmap.jl:146"
     ]
    }
   ],
   "source": [
    "# This code will fail because the different workers do not have the Â¨count_elements\" function\n",
    "@time begin\n",
    "n = length(big_array)\n",
    "n_processors = length(workers())\n",
    "splits_ind = [Int(x) for x in 1:(n/n_processors):(n+1)]\n",
    "big_array_splits = [big_array[x:y-1] for (x,y) in zip(splits_ind[1:end-1], splits_ind[2:end])]\n",
    "res = pmap(count_elements, big_array_splits)\n",
    "d = count_reduce(res)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition count_elements(Array{Int64, N<:Any}) in module Main at In[4]:2 overwritten at In[8]:2.\n"
     ]
    }
   ],
   "source": [
    "@everywhere function count_elements(array::Array{Int64})\n",
    "    n = length(array)\n",
    "    counts = Dict{Int64}{Int64}()\n",
    "    for i in array\n",
    "        if i in keys(counts)\n",
    "            counts[i] += 1 \n",
    "        else\n",
    "            counts[i] = 1\n",
    "        end\n",
    "    end\n",
    "    return counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.302563 seconds (29.68 k allocations: 764.246 MB, 7.40% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 10 entries:\n",
       "  7  => 9995828\n",
       "  4  => 10003840\n",
       "  9  => 10001185\n",
       "  10 => 9996515\n",
       "  2  => 10000655\n",
       "  3  => 9998257\n",
       "  8  => 10002993\n",
       "  5  => 9999068\n",
       "  6  => 10003080\n",
       "  1  => 9998579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    n = length(big_array)\n",
    "    n_processors = length(workers())\n",
    "    splits_ind = [Int(x) for x in 1:(n/n_processors):(n+1)]\n",
    "    big_array_splits = [big_array[x:y-1] for (x,y) in zip(splits_ind[1:end-1], splits_ind[2:end])]\n",
    "    res = pmap(count_elements, big_array_splits)\n",
    "    result_paralel = count_reduce(res);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Both computations yield to the exact same result\n",
    "result_paralel  == result_sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @spawn and fetch functions\n",
    "\n",
    "Using **```@spawn```** and **```fetch```** we can build our own pmaplike function.\n",
    "\n",
    "- **```@spawn```**: Creates a closure around an expression and runs it on an automatically-chosen process, returning a Future to the result.\n",
    "\n",
    "- **```fetch```**: Gets the computation returned from the Future object that we build using **```@spawn```**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition parallel_wordcount(Any, Any) in module Main at In[27]:7 overwritten at In[36]:7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "parallel_wordcount (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Splits input string into nprocs() equal-sized chunks (last one rounds up),\n",
    "# 2) @spawns wordcount() for each chunk to run in parallel. \n",
    "# 3) Then fetch()s results and performs count_reduce().\n",
    "\n",
    "function parallel_wordcount(big_array, n_processors)\n",
    "    \n",
    "    n = length(big_array)\n",
    "    splits_ind = [Int(x) for x in 1:(n/n_processors):(n+1)]\n",
    "    big_array_splits = [big_array[x:y-1] for (x,y) in zip(splits_ind[1:end-1], splits_ind[2:end])]\n",
    "    \n",
    "    partial_res = []\n",
    "    for subarray in big_array_splits\n",
    "        #r = remotecall(count_elements, subarray)\n",
    "        push!(partial_res, @spawn count_elements(subarray) )\n",
    "    end    \n",
    "    results = [fetch(r) for r in partial_res]\n",
    "    return count_reduce(results)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.293853 seconds (965 allocations: 762.993 MB, 4.63% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time r = parallel_wordcount(big_array, 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64,Int64} with 10 entries:\n",
       "  7  => 9995828\n",
       "  4  => 10003840\n",
       "  9  => 10001185\n",
       "  10 => 9996515\n",
       "  2  => 10000655\n",
       "  3  => 9998257\n",
       "  8  => 10002993\n",
       "  5  => 9999068\n",
       "  6  => 10003080\n",
       "  1  => 9998579"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us look at the code piece by piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future(2,1,72,Nullable{Any}())"
     ]
    }
   ],
   "source": [
    "#run a command on a different worker\n",
    "rmatrix = remotecall(2, rand, 2, 2)\n",
    "print(rmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(2,1,72,Nullable{Any}())"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2Ã2 Array{Float64,2}:\n",
       " 0.57138   0.113624\n",
       " 0.900078  0.490539"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(rmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partial_res = []\n",
    "for subarray in big_array_splits\n",
    "    r = remotecall(count_elements, subarray)\n",
    "    push!(partial_res, @spawn count_elements(subarray) )\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
